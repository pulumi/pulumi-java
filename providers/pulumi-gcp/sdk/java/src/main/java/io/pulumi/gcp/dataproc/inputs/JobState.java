// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package io.pulumi.gcp.dataproc.inputs;

import io.pulumi.core.Output;
import io.pulumi.core.annotations.InputImport;
import io.pulumi.gcp.dataproc.inputs.JobHadoopConfigGetArgs;
import io.pulumi.gcp.dataproc.inputs.JobHiveConfigGetArgs;
import io.pulumi.gcp.dataproc.inputs.JobPigConfigGetArgs;
import io.pulumi.gcp.dataproc.inputs.JobPlacementGetArgs;
import io.pulumi.gcp.dataproc.inputs.JobPysparkConfigGetArgs;
import io.pulumi.gcp.dataproc.inputs.JobReferenceGetArgs;
import io.pulumi.gcp.dataproc.inputs.JobSchedulingGetArgs;
import io.pulumi.gcp.dataproc.inputs.JobSparkConfigGetArgs;
import io.pulumi.gcp.dataproc.inputs.JobSparksqlConfigGetArgs;
import io.pulumi.gcp.dataproc.inputs.JobStatusGetArgs;
import java.lang.Boolean;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import javax.annotation.Nullable;


public final class JobState extends io.pulumi.resources.ResourceArgs {

    public static final JobState Empty = new JobState();

    /**
     * If present, the location of miscellaneous control files which may be used as part of job setup and handling. If not present, control files may be placed in the same location as driver_output_uri.
     * 
     */
    @InputImport(name="driverControlsFilesUri")
      private final @Nullable Output<String> driverControlsFilesUri;

    public Output<String> getDriverControlsFilesUri() {
        return this.driverControlsFilesUri == null ? Output.empty() : this.driverControlsFilesUri;
    }

    /**
     * A URI pointing to the location of the stdout of the job's driver program.
     * 
     */
    @InputImport(name="driverOutputResourceUri")
      private final @Nullable Output<String> driverOutputResourceUri;

    public Output<String> getDriverOutputResourceUri() {
        return this.driverOutputResourceUri == null ? Output.empty() : this.driverOutputResourceUri;
    }

    /**
     * By default, you can only delete inactive jobs within
     * Dataproc. Setting this to true, and calling destroy, will ensure that the
     * job is first cancelled before issuing the delete.
     * 
     */
    @InputImport(name="forceDelete")
      private final @Nullable Output<Boolean> forceDelete;

    public Output<Boolean> getForceDelete() {
        return this.forceDelete == null ? Output.empty() : this.forceDelete;
    }

    /**
     * The config of Hadoop job
     * 
     */
    @InputImport(name="hadoopConfig")
      private final @Nullable Output<JobHadoopConfigGetArgs> hadoopConfig;

    public Output<JobHadoopConfigGetArgs> getHadoopConfig() {
        return this.hadoopConfig == null ? Output.empty() : this.hadoopConfig;
    }

    /**
     * The config of hive job
     * 
     */
    @InputImport(name="hiveConfig")
      private final @Nullable Output<JobHiveConfigGetArgs> hiveConfig;

    public Output<JobHiveConfigGetArgs> getHiveConfig() {
        return this.hiveConfig == null ? Output.empty() : this.hiveConfig;
    }

    /**
     * The list of labels (key/value pairs) to add to the job.
     * 
     */
    @InputImport(name="labels")
      private final @Nullable Output<Map<String,String>> labels;

    public Output<Map<String,String>> getLabels() {
        return this.labels == null ? Output.empty() : this.labels;
    }

    /**
     * The config of pag job.
     * 
     */
    @InputImport(name="pigConfig")
      private final @Nullable Output<JobPigConfigGetArgs> pigConfig;

    public Output<JobPigConfigGetArgs> getPigConfig() {
        return this.pigConfig == null ? Output.empty() : this.pigConfig;
    }

    /**
     * The config of job placement.
     * 
     */
    @InputImport(name="placement")
      private final @Nullable Output<JobPlacementGetArgs> placement;

    public Output<JobPlacementGetArgs> getPlacement() {
        return this.placement == null ? Output.empty() : this.placement;
    }

    /**
     * The project in which the `cluster` can be found and jobs
     * subsequently run against. If it is not provided, the provider project is used.
     * 
     */
    @InputImport(name="project")
      private final @Nullable Output<String> project;

    public Output<String> getProject() {
        return this.project == null ? Output.empty() : this.project;
    }

    /**
     * The config of pySpark job.
     * 
     */
    @InputImport(name="pysparkConfig")
      private final @Nullable Output<JobPysparkConfigGetArgs> pysparkConfig;

    public Output<JobPysparkConfigGetArgs> getPysparkConfig() {
        return this.pysparkConfig == null ? Output.empty() : this.pysparkConfig;
    }

    /**
     * The reference of the job
     * 
     */
    @InputImport(name="reference")
      private final @Nullable Output<JobReferenceGetArgs> reference;

    public Output<JobReferenceGetArgs> getReference() {
        return this.reference == null ? Output.empty() : this.reference;
    }

    /**
     * The Cloud Dataproc region. This essentially determines which clusters are available
     * for this job to be submitted to. If not specified, defaults to `global`.
     * 
     */
    @InputImport(name="region")
      private final @Nullable Output<String> region;

    public Output<String> getRegion() {
        return this.region == null ? Output.empty() : this.region;
    }

    /**
     * Optional. Job scheduling configuration.
     * 
     */
    @InputImport(name="scheduling")
      private final @Nullable Output<JobSchedulingGetArgs> scheduling;

    public Output<JobSchedulingGetArgs> getScheduling() {
        return this.scheduling == null ? Output.empty() : this.scheduling;
    }

    /**
     * The config of the Spark job.
     * 
     */
    @InputImport(name="sparkConfig")
      private final @Nullable Output<JobSparkConfigGetArgs> sparkConfig;

    public Output<JobSparkConfigGetArgs> getSparkConfig() {
        return this.sparkConfig == null ? Output.empty() : this.sparkConfig;
    }

    /**
     * The config of SparkSql job
     * 
     */
    @InputImport(name="sparksqlConfig")
      private final @Nullable Output<JobSparksqlConfigGetArgs> sparksqlConfig;

    public Output<JobSparksqlConfigGetArgs> getSparksqlConfig() {
        return this.sparksqlConfig == null ? Output.empty() : this.sparksqlConfig;
    }

    /**
     * The status of the job.
     * 
     */
    @InputImport(name="statuses")
      private final @Nullable Output<List<JobStatusGetArgs>> statuses;

    public Output<List<JobStatusGetArgs>> getStatuses() {
        return this.statuses == null ? Output.empty() : this.statuses;
    }

    public JobState(
        @Nullable Output<String> driverControlsFilesUri,
        @Nullable Output<String> driverOutputResourceUri,
        @Nullable Output<Boolean> forceDelete,
        @Nullable Output<JobHadoopConfigGetArgs> hadoopConfig,
        @Nullable Output<JobHiveConfigGetArgs> hiveConfig,
        @Nullable Output<Map<String,String>> labels,
        @Nullable Output<JobPigConfigGetArgs> pigConfig,
        @Nullable Output<JobPlacementGetArgs> placement,
        @Nullable Output<String> project,
        @Nullable Output<JobPysparkConfigGetArgs> pysparkConfig,
        @Nullable Output<JobReferenceGetArgs> reference,
        @Nullable Output<String> region,
        @Nullable Output<JobSchedulingGetArgs> scheduling,
        @Nullable Output<JobSparkConfigGetArgs> sparkConfig,
        @Nullable Output<JobSparksqlConfigGetArgs> sparksqlConfig,
        @Nullable Output<List<JobStatusGetArgs>> statuses) {
        this.driverControlsFilesUri = driverControlsFilesUri;
        this.driverOutputResourceUri = driverOutputResourceUri;
        this.forceDelete = forceDelete;
        this.hadoopConfig = hadoopConfig;
        this.hiveConfig = hiveConfig;
        this.labels = labels;
        this.pigConfig = pigConfig;
        this.placement = placement;
        this.project = project;
        this.pysparkConfig = pysparkConfig;
        this.reference = reference;
        this.region = region;
        this.scheduling = scheduling;
        this.sparkConfig = sparkConfig;
        this.sparksqlConfig = sparksqlConfig;
        this.statuses = statuses;
    }

    private JobState() {
        this.driverControlsFilesUri = Output.empty();
        this.driverOutputResourceUri = Output.empty();
        this.forceDelete = Output.empty();
        this.hadoopConfig = Output.empty();
        this.hiveConfig = Output.empty();
        this.labels = Output.empty();
        this.pigConfig = Output.empty();
        this.placement = Output.empty();
        this.project = Output.empty();
        this.pysparkConfig = Output.empty();
        this.reference = Output.empty();
        this.region = Output.empty();
        this.scheduling = Output.empty();
        this.sparkConfig = Output.empty();
        this.sparksqlConfig = Output.empty();
        this.statuses = Output.empty();
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(JobState defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private @Nullable Output<String> driverControlsFilesUri;
        private @Nullable Output<String> driverOutputResourceUri;
        private @Nullable Output<Boolean> forceDelete;
        private @Nullable Output<JobHadoopConfigGetArgs> hadoopConfig;
        private @Nullable Output<JobHiveConfigGetArgs> hiveConfig;
        private @Nullable Output<Map<String,String>> labels;
        private @Nullable Output<JobPigConfigGetArgs> pigConfig;
        private @Nullable Output<JobPlacementGetArgs> placement;
        private @Nullable Output<String> project;
        private @Nullable Output<JobPysparkConfigGetArgs> pysparkConfig;
        private @Nullable Output<JobReferenceGetArgs> reference;
        private @Nullable Output<String> region;
        private @Nullable Output<JobSchedulingGetArgs> scheduling;
        private @Nullable Output<JobSparkConfigGetArgs> sparkConfig;
        private @Nullable Output<JobSparksqlConfigGetArgs> sparksqlConfig;
        private @Nullable Output<List<JobStatusGetArgs>> statuses;

        public Builder() {
    	      // Empty
        }

        public Builder(JobState defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.driverControlsFilesUri = defaults.driverControlsFilesUri;
    	      this.driverOutputResourceUri = defaults.driverOutputResourceUri;
    	      this.forceDelete = defaults.forceDelete;
    	      this.hadoopConfig = defaults.hadoopConfig;
    	      this.hiveConfig = defaults.hiveConfig;
    	      this.labels = defaults.labels;
    	      this.pigConfig = defaults.pigConfig;
    	      this.placement = defaults.placement;
    	      this.project = defaults.project;
    	      this.pysparkConfig = defaults.pysparkConfig;
    	      this.reference = defaults.reference;
    	      this.region = defaults.region;
    	      this.scheduling = defaults.scheduling;
    	      this.sparkConfig = defaults.sparkConfig;
    	      this.sparksqlConfig = defaults.sparksqlConfig;
    	      this.statuses = defaults.statuses;
        }

        public Builder driverControlsFilesUri(@Nullable Output<String> driverControlsFilesUri) {
            this.driverControlsFilesUri = driverControlsFilesUri;
            return this;
        }

        public Builder driverControlsFilesUri(@Nullable String driverControlsFilesUri) {
            this.driverControlsFilesUri = Output.ofNullable(driverControlsFilesUri);
            return this;
        }

        public Builder driverOutputResourceUri(@Nullable Output<String> driverOutputResourceUri) {
            this.driverOutputResourceUri = driverOutputResourceUri;
            return this;
        }

        public Builder driverOutputResourceUri(@Nullable String driverOutputResourceUri) {
            this.driverOutputResourceUri = Output.ofNullable(driverOutputResourceUri);
            return this;
        }

        public Builder forceDelete(@Nullable Output<Boolean> forceDelete) {
            this.forceDelete = forceDelete;
            return this;
        }

        public Builder forceDelete(@Nullable Boolean forceDelete) {
            this.forceDelete = Output.ofNullable(forceDelete);
            return this;
        }

        public Builder hadoopConfig(@Nullable Output<JobHadoopConfigGetArgs> hadoopConfig) {
            this.hadoopConfig = hadoopConfig;
            return this;
        }

        public Builder hadoopConfig(@Nullable JobHadoopConfigGetArgs hadoopConfig) {
            this.hadoopConfig = Output.ofNullable(hadoopConfig);
            return this;
        }

        public Builder hiveConfig(@Nullable Output<JobHiveConfigGetArgs> hiveConfig) {
            this.hiveConfig = hiveConfig;
            return this;
        }

        public Builder hiveConfig(@Nullable JobHiveConfigGetArgs hiveConfig) {
            this.hiveConfig = Output.ofNullable(hiveConfig);
            return this;
        }

        public Builder labels(@Nullable Output<Map<String,String>> labels) {
            this.labels = labels;
            return this;
        }

        public Builder labels(@Nullable Map<String,String> labels) {
            this.labels = Output.ofNullable(labels);
            return this;
        }

        public Builder pigConfig(@Nullable Output<JobPigConfigGetArgs> pigConfig) {
            this.pigConfig = pigConfig;
            return this;
        }

        public Builder pigConfig(@Nullable JobPigConfigGetArgs pigConfig) {
            this.pigConfig = Output.ofNullable(pigConfig);
            return this;
        }

        public Builder placement(@Nullable Output<JobPlacementGetArgs> placement) {
            this.placement = placement;
            return this;
        }

        public Builder placement(@Nullable JobPlacementGetArgs placement) {
            this.placement = Output.ofNullable(placement);
            return this;
        }

        public Builder project(@Nullable Output<String> project) {
            this.project = project;
            return this;
        }

        public Builder project(@Nullable String project) {
            this.project = Output.ofNullable(project);
            return this;
        }

        public Builder pysparkConfig(@Nullable Output<JobPysparkConfigGetArgs> pysparkConfig) {
            this.pysparkConfig = pysparkConfig;
            return this;
        }

        public Builder pysparkConfig(@Nullable JobPysparkConfigGetArgs pysparkConfig) {
            this.pysparkConfig = Output.ofNullable(pysparkConfig);
            return this;
        }

        public Builder reference(@Nullable Output<JobReferenceGetArgs> reference) {
            this.reference = reference;
            return this;
        }

        public Builder reference(@Nullable JobReferenceGetArgs reference) {
            this.reference = Output.ofNullable(reference);
            return this;
        }

        public Builder region(@Nullable Output<String> region) {
            this.region = region;
            return this;
        }

        public Builder region(@Nullable String region) {
            this.region = Output.ofNullable(region);
            return this;
        }

        public Builder scheduling(@Nullable Output<JobSchedulingGetArgs> scheduling) {
            this.scheduling = scheduling;
            return this;
        }

        public Builder scheduling(@Nullable JobSchedulingGetArgs scheduling) {
            this.scheduling = Output.ofNullable(scheduling);
            return this;
        }

        public Builder sparkConfig(@Nullable Output<JobSparkConfigGetArgs> sparkConfig) {
            this.sparkConfig = sparkConfig;
            return this;
        }

        public Builder sparkConfig(@Nullable JobSparkConfigGetArgs sparkConfig) {
            this.sparkConfig = Output.ofNullable(sparkConfig);
            return this;
        }

        public Builder sparksqlConfig(@Nullable Output<JobSparksqlConfigGetArgs> sparksqlConfig) {
            this.sparksqlConfig = sparksqlConfig;
            return this;
        }

        public Builder sparksqlConfig(@Nullable JobSparksqlConfigGetArgs sparksqlConfig) {
            this.sparksqlConfig = Output.ofNullable(sparksqlConfig);
            return this;
        }

        public Builder statuses(@Nullable Output<List<JobStatusGetArgs>> statuses) {
            this.statuses = statuses;
            return this;
        }

        public Builder statuses(@Nullable List<JobStatusGetArgs> statuses) {
            this.statuses = Output.ofNullable(statuses);
            return this;
        }
        public JobState build() {
            return new JobState(driverControlsFilesUri, driverOutputResourceUri, forceDelete, hadoopConfig, hiveConfig, labels, pigConfig, placement, project, pysparkConfig, reference, region, scheduling, sparkConfig, sparksqlConfig, statuses);
        }
    }
}
