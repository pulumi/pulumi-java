// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package io.pulumi.azurenative.datafactory.outputs;

import io.pulumi.azurenative.datafactory.outputs.AzureKeyVaultSecretReferenceResponse;
import io.pulumi.azurenative.datafactory.outputs.CredentialReferenceResponse;
import io.pulumi.azurenative.datafactory.outputs.IntegrationRuntimeReferenceResponse;
import io.pulumi.azurenative.datafactory.outputs.ParameterSpecificationResponse;
import io.pulumi.azurenative.datafactory.outputs.SecureStringResponse;
import io.pulumi.core.Either;
import io.pulumi.core.annotations.OutputCustomType;
import java.lang.Object;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@OutputCustomType
public final class AzureDatabricksLinkedServiceResponse {
    /**
     * Access token for databricks REST API. Refer to https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Either<AzureKeyVaultSecretReferenceResponse,SecureStringResponse> accessToken;
    /**
     * List of tags that can be used for describing the linked service.
     * 
     */
    private final @Nullable List<Object> annotations;
    /**
     * Required to specify MSI, if using Workspace resource id for databricks REST API. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object authentication;
    /**
     * The integration runtime reference.
     * 
     */
    private final @Nullable IntegrationRuntimeReferenceResponse connectVia;
    /**
     * The credential reference containing authentication information.
     * 
     */
    private final @Nullable CredentialReferenceResponse credential;
    /**
     * Linked service description.
     * 
     */
    private final @Nullable String description;
    /**
     * <REGION>.azuredatabricks.net, domain name of your Databricks deployment. Type: string (or Expression with resultType string).
     * 
     */
    private final Object domain;
    /**
     * The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object encryptedCredential;
    /**
     * The id of an existing interactive cluster that will be used for all runs of this activity. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object existingClusterId;
    /**
     * The id of an existing instance pool that will be used for all runs of this activity. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object instancePoolId;
    /**
     * Additional tags for cluster resources. This property is ignored in instance pool configurations.
     * 
     */
    private final @Nullable Map<String,Object> newClusterCustomTags;
    /**
     * The driver node type for the new job cluster. This property is ignored in instance pool configurations. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object newClusterDriverNodeType;
    /**
     * Enable the elastic disk on the new cluster. This property is now ignored, and takes the default elastic disk behavior in Databricks (elastic disks are always enabled). Type: boolean (or Expression with resultType boolean).
     * 
     */
    private final @Nullable Object newClusterEnableElasticDisk;
    /**
     * User-defined initialization scripts for the new cluster. Type: array of strings (or Expression with resultType array of strings).
     * 
     */
    private final @Nullable Object newClusterInitScripts;
    /**
     * Specify a location to deliver Spark driver, worker, and event logs. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object newClusterLogDestination;
    /**
     * The node type of the new job cluster. This property is required if newClusterVersion is specified and instancePoolId is not specified. If instancePoolId is specified, this property is ignored. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object newClusterNodeType;
    /**
     * If not using an existing interactive cluster, this specifies the number of worker nodes to use for the new job cluster or instance pool. For new job clusters, this a string-formatted Int32, like '1' means numOfWorker is 1 or '1:10' means auto-scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted Int32, and can only specify a fixed number of worker nodes, such as '2'. Required if newClusterVersion is specified. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object newClusterNumOfWorker;
    /**
     * A set of optional, user-specified Spark configuration key-value pairs.
     * 
     */
    private final @Nullable Map<String,Object> newClusterSparkConf;
    /**
     * A set of optional, user-specified Spark environment variables key-value pairs.
     * 
     */
    private final @Nullable Map<String,Object> newClusterSparkEnvVars;
    /**
     * If not using an existing interactive cluster, this specifies the Spark version of a new job cluster or instance pool nodes created for each run of this activity. Required if instancePoolId is specified. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object newClusterVersion;
    /**
     * Parameters for linked service.
     * 
     */
    private final @Nullable Map<String,ParameterSpecificationResponse> parameters;
    /**
     * The policy id for limiting the ability to configure clusters based on a user defined set of rules. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object policyId;
    /**
     * Type of linked service.
     * Expected value is 'AzureDatabricks'.
     * 
     */
    private final String type;
    /**
     * Workspace resource id for databricks REST API. Type: string (or Expression with resultType string).
     * 
     */
    private final @Nullable Object workspaceResourceId;

    @OutputCustomType.Constructor({"accessToken","annotations","authentication","connectVia","credential","description","domain","encryptedCredential","existingClusterId","instancePoolId","newClusterCustomTags","newClusterDriverNodeType","newClusterEnableElasticDisk","newClusterInitScripts","newClusterLogDestination","newClusterNodeType","newClusterNumOfWorker","newClusterSparkConf","newClusterSparkEnvVars","newClusterVersion","parameters","policyId","type","workspaceResourceId"})
    private AzureDatabricksLinkedServiceResponse(
        @Nullable Either<AzureKeyVaultSecretReferenceResponse,SecureStringResponse> accessToken,
        @Nullable List<Object> annotations,
        @Nullable Object authentication,
        @Nullable IntegrationRuntimeReferenceResponse connectVia,
        @Nullable CredentialReferenceResponse credential,
        @Nullable String description,
        Object domain,
        @Nullable Object encryptedCredential,
        @Nullable Object existingClusterId,
        @Nullable Object instancePoolId,
        @Nullable Map<String,Object> newClusterCustomTags,
        @Nullable Object newClusterDriverNodeType,
        @Nullable Object newClusterEnableElasticDisk,
        @Nullable Object newClusterInitScripts,
        @Nullable Object newClusterLogDestination,
        @Nullable Object newClusterNodeType,
        @Nullable Object newClusterNumOfWorker,
        @Nullable Map<String,Object> newClusterSparkConf,
        @Nullable Map<String,Object> newClusterSparkEnvVars,
        @Nullable Object newClusterVersion,
        @Nullable Map<String,ParameterSpecificationResponse> parameters,
        @Nullable Object policyId,
        String type,
        @Nullable Object workspaceResourceId) {
        this.accessToken = accessToken;
        this.annotations = annotations;
        this.authentication = authentication;
        this.connectVia = connectVia;
        this.credential = credential;
        this.description = description;
        this.domain = Objects.requireNonNull(domain);
        this.encryptedCredential = encryptedCredential;
        this.existingClusterId = existingClusterId;
        this.instancePoolId = instancePoolId;
        this.newClusterCustomTags = newClusterCustomTags;
        this.newClusterDriverNodeType = newClusterDriverNodeType;
        this.newClusterEnableElasticDisk = newClusterEnableElasticDisk;
        this.newClusterInitScripts = newClusterInitScripts;
        this.newClusterLogDestination = newClusterLogDestination;
        this.newClusterNodeType = newClusterNodeType;
        this.newClusterNumOfWorker = newClusterNumOfWorker;
        this.newClusterSparkConf = newClusterSparkConf;
        this.newClusterSparkEnvVars = newClusterSparkEnvVars;
        this.newClusterVersion = newClusterVersion;
        this.parameters = parameters;
        this.policyId = policyId;
        this.type = Objects.requireNonNull(type);
        this.workspaceResourceId = workspaceResourceId;
    }

    /**
     * Access token for databricks REST API. Refer to https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Either<AzureKeyVaultSecretReferenceResponse,SecureStringResponse>> getAccessToken() {
        return Optional.ofNullable(this.accessToken);
    }
    /**
     * List of tags that can be used for describing the linked service.
     * 
    */
    public List<Object> getAnnotations() {
        return this.annotations == null ? List.of() : this.annotations;
    }
    /**
     * Required to specify MSI, if using Workspace resource id for databricks REST API. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getAuthentication() {
        return Optional.ofNullable(this.authentication);
    }
    /**
     * The integration runtime reference.
     * 
    */
    public Optional<IntegrationRuntimeReferenceResponse> getConnectVia() {
        return Optional.ofNullable(this.connectVia);
    }
    /**
     * The credential reference containing authentication information.
     * 
    */
    public Optional<CredentialReferenceResponse> getCredential() {
        return Optional.ofNullable(this.credential);
    }
    /**
     * Linked service description.
     * 
    */
    public Optional<String> getDescription() {
        return Optional.ofNullable(this.description);
    }
    /**
     * <REGION>.azuredatabricks.net, domain name of your Databricks deployment. Type: string (or Expression with resultType string).
     * 
    */
    public Object getDomain() {
        return this.domain;
    }
    /**
     * The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getEncryptedCredential() {
        return Optional.ofNullable(this.encryptedCredential);
    }
    /**
     * The id of an existing interactive cluster that will be used for all runs of this activity. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getExistingClusterId() {
        return Optional.ofNullable(this.existingClusterId);
    }
    /**
     * The id of an existing instance pool that will be used for all runs of this activity. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getInstancePoolId() {
        return Optional.ofNullable(this.instancePoolId);
    }
    /**
     * Additional tags for cluster resources. This property is ignored in instance pool configurations.
     * 
    */
    public Map<String,Object> getNewClusterCustomTags() {
        return this.newClusterCustomTags == null ? Map.of() : this.newClusterCustomTags;
    }
    /**
     * The driver node type for the new job cluster. This property is ignored in instance pool configurations. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getNewClusterDriverNodeType() {
        return Optional.ofNullable(this.newClusterDriverNodeType);
    }
    /**
     * Enable the elastic disk on the new cluster. This property is now ignored, and takes the default elastic disk behavior in Databricks (elastic disks are always enabled). Type: boolean (or Expression with resultType boolean).
     * 
    */
    public Optional<Object> getNewClusterEnableElasticDisk() {
        return Optional.ofNullable(this.newClusterEnableElasticDisk);
    }
    /**
     * User-defined initialization scripts for the new cluster. Type: array of strings (or Expression with resultType array of strings).
     * 
    */
    public Optional<Object> getNewClusterInitScripts() {
        return Optional.ofNullable(this.newClusterInitScripts);
    }
    /**
     * Specify a location to deliver Spark driver, worker, and event logs. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getNewClusterLogDestination() {
        return Optional.ofNullable(this.newClusterLogDestination);
    }
    /**
     * The node type of the new job cluster. This property is required if newClusterVersion is specified and instancePoolId is not specified. If instancePoolId is specified, this property is ignored. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getNewClusterNodeType() {
        return Optional.ofNullable(this.newClusterNodeType);
    }
    /**
     * If not using an existing interactive cluster, this specifies the number of worker nodes to use for the new job cluster or instance pool. For new job clusters, this a string-formatted Int32, like '1' means numOfWorker is 1 or '1:10' means auto-scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted Int32, and can only specify a fixed number of worker nodes, such as '2'. Required if newClusterVersion is specified. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getNewClusterNumOfWorker() {
        return Optional.ofNullable(this.newClusterNumOfWorker);
    }
    /**
     * A set of optional, user-specified Spark configuration key-value pairs.
     * 
    */
    public Map<String,Object> getNewClusterSparkConf() {
        return this.newClusterSparkConf == null ? Map.of() : this.newClusterSparkConf;
    }
    /**
     * A set of optional, user-specified Spark environment variables key-value pairs.
     * 
    */
    public Map<String,Object> getNewClusterSparkEnvVars() {
        return this.newClusterSparkEnvVars == null ? Map.of() : this.newClusterSparkEnvVars;
    }
    /**
     * If not using an existing interactive cluster, this specifies the Spark version of a new job cluster or instance pool nodes created for each run of this activity. Required if instancePoolId is specified. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getNewClusterVersion() {
        return Optional.ofNullable(this.newClusterVersion);
    }
    /**
     * Parameters for linked service.
     * 
    */
    public Map<String,ParameterSpecificationResponse> getParameters() {
        return this.parameters == null ? Map.of() : this.parameters;
    }
    /**
     * The policy id for limiting the ability to configure clusters based on a user defined set of rules. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getPolicyId() {
        return Optional.ofNullable(this.policyId);
    }
    /**
     * Type of linked service.
     * Expected value is 'AzureDatabricks'.
     * 
    */
    public String getType() {
        return this.type;
    }
    /**
     * Workspace resource id for databricks REST API. Type: string (or Expression with resultType string).
     * 
    */
    public Optional<Object> getWorkspaceResourceId() {
        return Optional.ofNullable(this.workspaceResourceId);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(AzureDatabricksLinkedServiceResponse defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private @Nullable Either<AzureKeyVaultSecretReferenceResponse,SecureStringResponse> accessToken;
        private @Nullable List<Object> annotations;
        private @Nullable Object authentication;
        private @Nullable IntegrationRuntimeReferenceResponse connectVia;
        private @Nullable CredentialReferenceResponse credential;
        private @Nullable String description;
        private Object domain;
        private @Nullable Object encryptedCredential;
        private @Nullable Object existingClusterId;
        private @Nullable Object instancePoolId;
        private @Nullable Map<String,Object> newClusterCustomTags;
        private @Nullable Object newClusterDriverNodeType;
        private @Nullable Object newClusterEnableElasticDisk;
        private @Nullable Object newClusterInitScripts;
        private @Nullable Object newClusterLogDestination;
        private @Nullable Object newClusterNodeType;
        private @Nullable Object newClusterNumOfWorker;
        private @Nullable Map<String,Object> newClusterSparkConf;
        private @Nullable Map<String,Object> newClusterSparkEnvVars;
        private @Nullable Object newClusterVersion;
        private @Nullable Map<String,ParameterSpecificationResponse> parameters;
        private @Nullable Object policyId;
        private String type;
        private @Nullable Object workspaceResourceId;

        public Builder() {
    	      // Empty
        }

        public Builder(AzureDatabricksLinkedServiceResponse defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.accessToken = defaults.accessToken;
    	      this.annotations = defaults.annotations;
    	      this.authentication = defaults.authentication;
    	      this.connectVia = defaults.connectVia;
    	      this.credential = defaults.credential;
    	      this.description = defaults.description;
    	      this.domain = defaults.domain;
    	      this.encryptedCredential = defaults.encryptedCredential;
    	      this.existingClusterId = defaults.existingClusterId;
    	      this.instancePoolId = defaults.instancePoolId;
    	      this.newClusterCustomTags = defaults.newClusterCustomTags;
    	      this.newClusterDriverNodeType = defaults.newClusterDriverNodeType;
    	      this.newClusterEnableElasticDisk = defaults.newClusterEnableElasticDisk;
    	      this.newClusterInitScripts = defaults.newClusterInitScripts;
    	      this.newClusterLogDestination = defaults.newClusterLogDestination;
    	      this.newClusterNodeType = defaults.newClusterNodeType;
    	      this.newClusterNumOfWorker = defaults.newClusterNumOfWorker;
    	      this.newClusterSparkConf = defaults.newClusterSparkConf;
    	      this.newClusterSparkEnvVars = defaults.newClusterSparkEnvVars;
    	      this.newClusterVersion = defaults.newClusterVersion;
    	      this.parameters = defaults.parameters;
    	      this.policyId = defaults.policyId;
    	      this.type = defaults.type;
    	      this.workspaceResourceId = defaults.workspaceResourceId;
        }

        public Builder setAccessToken(@Nullable Either<AzureKeyVaultSecretReferenceResponse,SecureStringResponse> accessToken) {
            this.accessToken = accessToken;
            return this;
        }

        public Builder setAnnotations(@Nullable List<Object> annotations) {
            this.annotations = annotations;
            return this;
        }

        public Builder setAuthentication(@Nullable Object authentication) {
            this.authentication = authentication;
            return this;
        }

        public Builder setConnectVia(@Nullable IntegrationRuntimeReferenceResponse connectVia) {
            this.connectVia = connectVia;
            return this;
        }

        public Builder setCredential(@Nullable CredentialReferenceResponse credential) {
            this.credential = credential;
            return this;
        }

        public Builder setDescription(@Nullable String description) {
            this.description = description;
            return this;
        }

        public Builder setDomain(Object domain) {
            this.domain = Objects.requireNonNull(domain);
            return this;
        }

        public Builder setEncryptedCredential(@Nullable Object encryptedCredential) {
            this.encryptedCredential = encryptedCredential;
            return this;
        }

        public Builder setExistingClusterId(@Nullable Object existingClusterId) {
            this.existingClusterId = existingClusterId;
            return this;
        }

        public Builder setInstancePoolId(@Nullable Object instancePoolId) {
            this.instancePoolId = instancePoolId;
            return this;
        }

        public Builder setNewClusterCustomTags(@Nullable Map<String,Object> newClusterCustomTags) {
            this.newClusterCustomTags = newClusterCustomTags;
            return this;
        }

        public Builder setNewClusterDriverNodeType(@Nullable Object newClusterDriverNodeType) {
            this.newClusterDriverNodeType = newClusterDriverNodeType;
            return this;
        }

        public Builder setNewClusterEnableElasticDisk(@Nullable Object newClusterEnableElasticDisk) {
            this.newClusterEnableElasticDisk = newClusterEnableElasticDisk;
            return this;
        }

        public Builder setNewClusterInitScripts(@Nullable Object newClusterInitScripts) {
            this.newClusterInitScripts = newClusterInitScripts;
            return this;
        }

        public Builder setNewClusterLogDestination(@Nullable Object newClusterLogDestination) {
            this.newClusterLogDestination = newClusterLogDestination;
            return this;
        }

        public Builder setNewClusterNodeType(@Nullable Object newClusterNodeType) {
            this.newClusterNodeType = newClusterNodeType;
            return this;
        }

        public Builder setNewClusterNumOfWorker(@Nullable Object newClusterNumOfWorker) {
            this.newClusterNumOfWorker = newClusterNumOfWorker;
            return this;
        }

        public Builder setNewClusterSparkConf(@Nullable Map<String,Object> newClusterSparkConf) {
            this.newClusterSparkConf = newClusterSparkConf;
            return this;
        }

        public Builder setNewClusterSparkEnvVars(@Nullable Map<String,Object> newClusterSparkEnvVars) {
            this.newClusterSparkEnvVars = newClusterSparkEnvVars;
            return this;
        }

        public Builder setNewClusterVersion(@Nullable Object newClusterVersion) {
            this.newClusterVersion = newClusterVersion;
            return this;
        }

        public Builder setParameters(@Nullable Map<String,ParameterSpecificationResponse> parameters) {
            this.parameters = parameters;
            return this;
        }

        public Builder setPolicyId(@Nullable Object policyId) {
            this.policyId = policyId;
            return this;
        }

        public Builder setType(String type) {
            this.type = Objects.requireNonNull(type);
            return this;
        }

        public Builder setWorkspaceResourceId(@Nullable Object workspaceResourceId) {
            this.workspaceResourceId = workspaceResourceId;
            return this;
        }
        public AzureDatabricksLinkedServiceResponse build() {
            return new AzureDatabricksLinkedServiceResponse(accessToken, annotations, authentication, connectVia, credential, description, domain, encryptedCredential, existingClusterId, instancePoolId, newClusterCustomTags, newClusterDriverNodeType, newClusterEnableElasticDisk, newClusterInitScripts, newClusterLogDestination, newClusterNodeType, newClusterNumOfWorker, newClusterSparkConf, newClusterSparkEnvVars, newClusterVersion, parameters, policyId, type, workspaceResourceId);
        }
    }
}
