// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.googlenative.ml.v1.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.googlenative.ml.v1.inputs.GoogleCloudMlV1__MetricSpecArgs;
import java.lang.Integer;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


/**
 * Options for automatically scaling a model.
 * 
 */
public final class GoogleCloudMlV1__AutoScalingArgs extends com.pulumi.resources.ResourceArgs {

    public static final GoogleCloudMlV1__AutoScalingArgs Empty = new GoogleCloudMlV1__AutoScalingArgs();

    /**
     * The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability.
     * 
     */
    @Import(name="maxNodes")
    private @Nullable Output<Integer> maxNodes;

    /**
     * @return The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability.
     * 
     */
    public Optional<Output<Integer>> maxNodes() {
        return Optional.ofNullable(this.maxNodes);
    }

    /**
     * MetricSpec contains the specifications to use to calculate the desired nodes count.
     * 
     */
    @Import(name="metrics")
    private @Nullable Output<List<GoogleCloudMlV1__MetricSpecArgs>> metrics;

    /**
     * @return MetricSpec contains the specifications to use to calculate the desired nodes count.
     * 
     */
    public Optional<Output<List<GoogleCloudMlV1__MetricSpecArgs>>> metrics() {
        return Optional.ofNullable(this.metrics);
    }

    /**
     * Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least `rate` * `min_nodes` * number of hours since last billing cycle, where `rate` is the cost per node-hour as documented in the [pricing guide](/ml-engine/docs/pricing), even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least `min_nodes`. You will be charged for the time in which additional nodes are used. If `min_nodes` is not specified and AutoScaling is used with a [legacy (MLS1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If `min_nodes` is not specified and AutoScaling is used with a [Compute Engine (N1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 1. `min_nodes` must be at least 1 for use with a Compute Engine machine type. You can set `min_nodes` when creating the model version, and you can also update `min_nodes` for an existing version: update_body.json: { &#39;autoScaling&#39;: { &#39;minNodes&#39;: 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/*{@literal /}models/*{@literal /}versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json
     * 
     */
    @Import(name="minNodes")
    private @Nullable Output<Integer> minNodes;

    /**
     * @return Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least `rate` * `min_nodes` * number of hours since last billing cycle, where `rate` is the cost per node-hour as documented in the [pricing guide](/ml-engine/docs/pricing), even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least `min_nodes`. You will be charged for the time in which additional nodes are used. If `min_nodes` is not specified and AutoScaling is used with a [legacy (MLS1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If `min_nodes` is not specified and AutoScaling is used with a [Compute Engine (N1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 1. `min_nodes` must be at least 1 for use with a Compute Engine machine type. You can set `min_nodes` when creating the model version, and you can also update `min_nodes` for an existing version: update_body.json: { &#39;autoScaling&#39;: { &#39;minNodes&#39;: 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/*{@literal /}models/*{@literal /}versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json
     * 
     */
    public Optional<Output<Integer>> minNodes() {
        return Optional.ofNullable(this.minNodes);
    }

    private GoogleCloudMlV1__AutoScalingArgs() {}

    private GoogleCloudMlV1__AutoScalingArgs(GoogleCloudMlV1__AutoScalingArgs $) {
        this.maxNodes = $.maxNodes;
        this.metrics = $.metrics;
        this.minNodes = $.minNodes;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(GoogleCloudMlV1__AutoScalingArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private GoogleCloudMlV1__AutoScalingArgs $;

        public Builder() {
            $ = new GoogleCloudMlV1__AutoScalingArgs();
        }

        public Builder(GoogleCloudMlV1__AutoScalingArgs defaults) {
            $ = new GoogleCloudMlV1__AutoScalingArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param maxNodes The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability.
         * 
         * @return builder
         * 
         */
        public Builder maxNodes(@Nullable Output<Integer> maxNodes) {
            $.maxNodes = maxNodes;
            return this;
        }

        /**
         * @param maxNodes The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability.
         * 
         * @return builder
         * 
         */
        public Builder maxNodes(Integer maxNodes) {
            return maxNodes(Output.of(maxNodes));
        }

        /**
         * @param metrics MetricSpec contains the specifications to use to calculate the desired nodes count.
         * 
         * @return builder
         * 
         */
        public Builder metrics(@Nullable Output<List<GoogleCloudMlV1__MetricSpecArgs>> metrics) {
            $.metrics = metrics;
            return this;
        }

        /**
         * @param metrics MetricSpec contains the specifications to use to calculate the desired nodes count.
         * 
         * @return builder
         * 
         */
        public Builder metrics(List<GoogleCloudMlV1__MetricSpecArgs> metrics) {
            return metrics(Output.of(metrics));
        }

        /**
         * @param metrics MetricSpec contains the specifications to use to calculate the desired nodes count.
         * 
         * @return builder
         * 
         */
        public Builder metrics(GoogleCloudMlV1__MetricSpecArgs... metrics) {
            return metrics(List.of(metrics));
        }

        /**
         * @param minNodes Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least `rate` * `min_nodes` * number of hours since last billing cycle, where `rate` is the cost per node-hour as documented in the [pricing guide](/ml-engine/docs/pricing), even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least `min_nodes`. You will be charged for the time in which additional nodes are used. If `min_nodes` is not specified and AutoScaling is used with a [legacy (MLS1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If `min_nodes` is not specified and AutoScaling is used with a [Compute Engine (N1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 1. `min_nodes` must be at least 1 for use with a Compute Engine machine type. You can set `min_nodes` when creating the model version, and you can also update `min_nodes` for an existing version: update_body.json: { &#39;autoScaling&#39;: { &#39;minNodes&#39;: 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/*{@literal /}models/*{@literal /}versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json
         * 
         * @return builder
         * 
         */
        public Builder minNodes(@Nullable Output<Integer> minNodes) {
            $.minNodes = minNodes;
            return this;
        }

        /**
         * @param minNodes Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least `rate` * `min_nodes` * number of hours since last billing cycle, where `rate` is the cost per node-hour as documented in the [pricing guide](/ml-engine/docs/pricing), even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least `min_nodes`. You will be charged for the time in which additional nodes are used. If `min_nodes` is not specified and AutoScaling is used with a [legacy (MLS1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If `min_nodes` is not specified and AutoScaling is used with a [Compute Engine (N1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 1. `min_nodes` must be at least 1 for use with a Compute Engine machine type. You can set `min_nodes` when creating the model version, and you can also update `min_nodes` for an existing version: update_body.json: { &#39;autoScaling&#39;: { &#39;minNodes&#39;: 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/*{@literal /}models/*{@literal /}versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json
         * 
         * @return builder
         * 
         */
        public Builder minNodes(Integer minNodes) {
            return minNodes(Output.of(minNodes));
        }

        public GoogleCloudMlV1__AutoScalingArgs build() {
            return $;
        }
    }

}
