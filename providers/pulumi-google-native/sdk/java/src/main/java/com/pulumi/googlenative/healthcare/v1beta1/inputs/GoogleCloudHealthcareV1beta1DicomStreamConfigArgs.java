// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.googlenative.healthcare.v1beta1.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.googlenative.healthcare.v1beta1.inputs.GoogleCloudHealthcareV1beta1DicomBigQueryDestinationArgs;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


/**
 * StreamConfig specifies configuration for a streaming DICOM export.
 * 
 */
public final class GoogleCloudHealthcareV1beta1DicomStreamConfigArgs extends com.pulumi.resources.ResourceArgs {

    public static final GoogleCloudHealthcareV1beta1DicomStreamConfigArgs Empty = new GoogleCloudHealthcareV1beta1DicomStreamConfigArgs();

    /**
     * Results are appended to this table. The server creates a new table in the given BigQuery dataset if the specified table does not exist. To enable the Cloud Healthcare API to write to your BigQuery table, you must give the Cloud Healthcare API service account the bigquery.dataEditor role. The service account is: `service-{PROJECT_NUMBER}@gcp-sa-healthcare.iam.gserviceaccount.com`. The PROJECT_NUMBER identifies the project that the DICOM store resides in. To get the project number, go to the Cloud Console Dashboard. It is recommended to not have a custom schema in the destination table which could conflict with the schema created by the Cloud Healthcare API. Instance deletions are not applied to the destination table. The destination&#39;s table schema will be automatically updated in case a new instance&#39;s data is incompatible with the current schema. The schema should not be updated manually as this can cause incompatibilies that cannot be resolved automatically. One resolution in this case is to delete the incompatible table and let the server recreate one, though the newly created table only contains data after the table recreation. BigQuery imposes a 1 MB limit on streaming insert row size, therefore any instance that generates more than 1 MB of BigQuery data will not be streamed. If an instance cannot be streamed to BigQuery, errors will be logged to Cloud Logging (see [Viewing error logs in Cloud Logging](https://cloud.google.com/healthcare/docs/how-tos/logging)).
     * 
     */
    @Import(name="bigqueryDestination")
    private @Nullable Output<GoogleCloudHealthcareV1beta1DicomBigQueryDestinationArgs> bigqueryDestination;

    /**
     * @return Results are appended to this table. The server creates a new table in the given BigQuery dataset if the specified table does not exist. To enable the Cloud Healthcare API to write to your BigQuery table, you must give the Cloud Healthcare API service account the bigquery.dataEditor role. The service account is: `service-{PROJECT_NUMBER}@gcp-sa-healthcare.iam.gserviceaccount.com`. The PROJECT_NUMBER identifies the project that the DICOM store resides in. To get the project number, go to the Cloud Console Dashboard. It is recommended to not have a custom schema in the destination table which could conflict with the schema created by the Cloud Healthcare API. Instance deletions are not applied to the destination table. The destination&#39;s table schema will be automatically updated in case a new instance&#39;s data is incompatible with the current schema. The schema should not be updated manually as this can cause incompatibilies that cannot be resolved automatically. One resolution in this case is to delete the incompatible table and let the server recreate one, though the newly created table only contains data after the table recreation. BigQuery imposes a 1 MB limit on streaming insert row size, therefore any instance that generates more than 1 MB of BigQuery data will not be streamed. If an instance cannot be streamed to BigQuery, errors will be logged to Cloud Logging (see [Viewing error logs in Cloud Logging](https://cloud.google.com/healthcare/docs/how-tos/logging)).
     * 
     */
    public Optional<Output<GoogleCloudHealthcareV1beta1DicomBigQueryDestinationArgs>> bigqueryDestination() {
        return Optional.ofNullable(this.bigqueryDestination);
    }

    private GoogleCloudHealthcareV1beta1DicomStreamConfigArgs() {}

    private GoogleCloudHealthcareV1beta1DicomStreamConfigArgs(GoogleCloudHealthcareV1beta1DicomStreamConfigArgs $) {
        this.bigqueryDestination = $.bigqueryDestination;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(GoogleCloudHealthcareV1beta1DicomStreamConfigArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private GoogleCloudHealthcareV1beta1DicomStreamConfigArgs $;

        public Builder() {
            $ = new GoogleCloudHealthcareV1beta1DicomStreamConfigArgs();
        }

        public Builder(GoogleCloudHealthcareV1beta1DicomStreamConfigArgs defaults) {
            $ = new GoogleCloudHealthcareV1beta1DicomStreamConfigArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param bigqueryDestination Results are appended to this table. The server creates a new table in the given BigQuery dataset if the specified table does not exist. To enable the Cloud Healthcare API to write to your BigQuery table, you must give the Cloud Healthcare API service account the bigquery.dataEditor role. The service account is: `service-{PROJECT_NUMBER}@gcp-sa-healthcare.iam.gserviceaccount.com`. The PROJECT_NUMBER identifies the project that the DICOM store resides in. To get the project number, go to the Cloud Console Dashboard. It is recommended to not have a custom schema in the destination table which could conflict with the schema created by the Cloud Healthcare API. Instance deletions are not applied to the destination table. The destination&#39;s table schema will be automatically updated in case a new instance&#39;s data is incompatible with the current schema. The schema should not be updated manually as this can cause incompatibilies that cannot be resolved automatically. One resolution in this case is to delete the incompatible table and let the server recreate one, though the newly created table only contains data after the table recreation. BigQuery imposes a 1 MB limit on streaming insert row size, therefore any instance that generates more than 1 MB of BigQuery data will not be streamed. If an instance cannot be streamed to BigQuery, errors will be logged to Cloud Logging (see [Viewing error logs in Cloud Logging](https://cloud.google.com/healthcare/docs/how-tos/logging)).
         * 
         * @return builder
         * 
         */
        public Builder bigqueryDestination(@Nullable Output<GoogleCloudHealthcareV1beta1DicomBigQueryDestinationArgs> bigqueryDestination) {
            $.bigqueryDestination = bigqueryDestination;
            return this;
        }

        /**
         * @param bigqueryDestination Results are appended to this table. The server creates a new table in the given BigQuery dataset if the specified table does not exist. To enable the Cloud Healthcare API to write to your BigQuery table, you must give the Cloud Healthcare API service account the bigquery.dataEditor role. The service account is: `service-{PROJECT_NUMBER}@gcp-sa-healthcare.iam.gserviceaccount.com`. The PROJECT_NUMBER identifies the project that the DICOM store resides in. To get the project number, go to the Cloud Console Dashboard. It is recommended to not have a custom schema in the destination table which could conflict with the schema created by the Cloud Healthcare API. Instance deletions are not applied to the destination table. The destination&#39;s table schema will be automatically updated in case a new instance&#39;s data is incompatible with the current schema. The schema should not be updated manually as this can cause incompatibilies that cannot be resolved automatically. One resolution in this case is to delete the incompatible table and let the server recreate one, though the newly created table only contains data after the table recreation. BigQuery imposes a 1 MB limit on streaming insert row size, therefore any instance that generates more than 1 MB of BigQuery data will not be streamed. If an instance cannot be streamed to BigQuery, errors will be logged to Cloud Logging (see [Viewing error logs in Cloud Logging](https://cloud.google.com/healthcare/docs/how-tos/logging)).
         * 
         * @return builder
         * 
         */
        public Builder bigqueryDestination(GoogleCloudHealthcareV1beta1DicomBigQueryDestinationArgs bigqueryDestination) {
            return bigqueryDestination(Output.of(bigqueryDestination));
        }

        public GoogleCloudHealthcareV1beta1DicomStreamConfigArgs build() {
            return $;
        }
    }

}
