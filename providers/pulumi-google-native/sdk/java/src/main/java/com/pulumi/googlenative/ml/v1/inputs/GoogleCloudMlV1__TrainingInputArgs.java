// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.googlenative.ml.v1.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.googlenative.ml.v1.enums.GoogleCloudMlV1__TrainingInputScaleTier;
import com.pulumi.googlenative.ml.v1.inputs.GoogleCloudMlV1__EncryptionConfigArgs;
import com.pulumi.googlenative.ml.v1.inputs.GoogleCloudMlV1__HyperparameterSpecArgs;
import com.pulumi.googlenative.ml.v1.inputs.GoogleCloudMlV1__ReplicaConfigArgs;
import com.pulumi.googlenative.ml.v1.inputs.GoogleCloudMlV1__SchedulingArgs;
import java.lang.Boolean;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


/**
 * Represents input parameters for a training job. When using the gcloud command to submit your training job, you can specify the input parameters as command-line arguments and/or in a YAML configuration file referenced from the --config command-line argument. For details, see the guide to [submitting a training job](/ai-platform/training/docs/training-jobs).
 * 
 */
public final class GoogleCloudMlV1__TrainingInputArgs extends com.pulumi.resources.ResourceArgs {

    public static final GoogleCloudMlV1__TrainingInputArgs Empty = new GoogleCloudMlV1__TrainingInputArgs();

    /**
     * Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container&#39;s `ENTRYPOINT` command.
     * 
     */
    @Import(name="args")
    private @Nullable Output<List<String>> args;

    /**
     * @return Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container&#39;s `ENTRYPOINT` command.
     * 
     */
    public Optional<Output<List<String>>> args() {
        return Optional.ofNullable(this.args);
    }

    /**
     * Optional. Whether you want AI Platform Training to enable [interactive shell access](https://cloud.google.com/ai-platform/training/docs/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by TrainingOutput.web_access_uris or HyperparameterOutput.web_access_uris (within TrainingOutput.trials).
     * 
     */
    @Import(name="enableWebAccess")
    private @Nullable Output<Boolean> enableWebAccess;

    /**
     * @return Optional. Whether you want AI Platform Training to enable [interactive shell access](https://cloud.google.com/ai-platform/training/docs/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by TrainingOutput.web_access_uris or HyperparameterOutput.web_access_uris (within TrainingOutput.trials).
     * 
     */
    public Optional<Output<Boolean>> enableWebAccess() {
        return Optional.ofNullable(this.enableWebAccess);
    }

    /**
     * Optional. Options for using customer-managed encryption keys (CMEK) to protect resources created by a training job, instead of using Google&#39;s default encryption. If this is set, then all resources created by the training job will be encrypted with the customer-managed encryption key that you specify. [Learn how and when to use CMEK with AI Platform Training](/ai-platform/training/docs/cmek).
     * 
     */
    @Import(name="encryptionConfig")
    private @Nullable Output<GoogleCloudMlV1__EncryptionConfigArgs> encryptionConfig;

    /**
     * @return Optional. Options for using customer-managed encryption keys (CMEK) to protect resources created by a training job, instead of using Google&#39;s default encryption. If this is set, then all resources created by the training job will be encrypted with the customer-managed encryption key that you specify. [Learn how and when to use CMEK with AI Platform Training](/ai-platform/training/docs/cmek).
     * 
     */
    public Optional<Output<GoogleCloudMlV1__EncryptionConfigArgs>> encryptionConfig() {
        return Optional.ofNullable(this.encryptionConfig);
    }

    /**
     * Optional. The configuration for evaluators. You should only set `evaluatorConfig.acceleratorConfig` if `evaluatorType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `evaluatorConfig.imageUri` only if you build a custom image for your evaluator. If `evaluatorConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
     * 
     */
    @Import(name="evaluatorConfig")
    private @Nullable Output<GoogleCloudMlV1__ReplicaConfigArgs> evaluatorConfig;

    /**
     * @return Optional. The configuration for evaluators. You should only set `evaluatorConfig.acceleratorConfig` if `evaluatorType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `evaluatorConfig.imageUri` only if you build a custom image for your evaluator. If `evaluatorConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
     * 
     */
    public Optional<Output<GoogleCloudMlV1__ReplicaConfigArgs>> evaluatorConfig() {
        return Optional.ofNullable(this.evaluatorConfig);
    }

    /**
     * Optional. The number of evaluator replicas to use for the training job. Each replica in the cluster will be of the type specified in `evaluator_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `evaluator_type`. The default value is zero.
     * 
     */
    @Import(name="evaluatorCount")
    private @Nullable Output<String> evaluatorCount;

    /**
     * @return Optional. The number of evaluator replicas to use for the training job. Each replica in the cluster will be of the type specified in `evaluator_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `evaluator_type`. The default value is zero.
     * 
     */
    public Optional<Output<String>> evaluatorCount() {
        return Optional.ofNullable(this.evaluatorCount);
    }

    /**
     * Optional. Specifies the type of virtual machine to use for your training job&#39;s evaluator nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `evaluatorCount` is greater than zero.
     * 
     */
    @Import(name="evaluatorType")
    private @Nullable Output<String> evaluatorType;

    /**
     * @return Optional. Specifies the type of virtual machine to use for your training job&#39;s evaluator nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `evaluatorCount` is greater than zero.
     * 
     */
    public Optional<Output<String>> evaluatorType() {
        return Optional.ofNullable(this.evaluatorType);
    }

    /**
     * Optional. The set of Hyperparameters to tune.
     * 
     */
    @Import(name="hyperparameters")
    private @Nullable Output<GoogleCloudMlV1__HyperparameterSpecArgs> hyperparameters;

    /**
     * @return Optional. The set of Hyperparameters to tune.
     * 
     */
    public Optional<Output<GoogleCloudMlV1__HyperparameterSpecArgs>> hyperparameters() {
        return Optional.ofNullable(this.hyperparameters);
    }

    /**
     * Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the &#39;--job-dir&#39; command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training.
     * 
     */
    @Import(name="jobDir")
    private @Nullable Output<String> jobDir;

    /**
     * @return Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the &#39;--job-dir&#39; command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training.
     * 
     */
    public Optional<Output<String>> jobDir() {
        return Optional.ofNullable(this.jobDir);
    }

    /**
     * Optional. The configuration for your master worker. You should only set `masterConfig.acceleratorConfig` if `masterType` is set to a Compute Engine machine type. Learn about [restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `masterConfig.imageUri` only if you build a custom image. Only one of `masterConfig.imageUri` and `runtimeVersion` should be set. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
     * 
     */
    @Import(name="masterConfig")
    private @Nullable Output<GoogleCloudMlV1__ReplicaConfigArgs> masterConfig;

    /**
     * @return Optional. The configuration for your master worker. You should only set `masterConfig.acceleratorConfig` if `masterType` is set to a Compute Engine machine type. Learn about [restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `masterConfig.imageUri` only if you build a custom image. Only one of `masterConfig.imageUri` and `runtimeVersion` should be set. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
     * 
     */
    public Optional<Output<GoogleCloudMlV1__ReplicaConfigArgs>> masterConfig() {
        return Optional.ofNullable(this.masterConfig);
    }

    /**
     * Optional. Specifies the type of virtual machine to use for your training job&#39;s master worker. You must specify this field when `scaleTier` is set to `CUSTOM`. You can use certain Compute Engine machine types directly in this field. See the [list of compatible Compute Engine machine types](/ai-platform/training/docs/machine-types#compute-engine-machine-types). Alternatively, you can use the certain legacy machine types in this field. See the [list of legacy machine types](/ai-platform/training/docs/machine-types#legacy-machine-types). Finally, if you want to use a TPU for training, specify `cloud_tpu` in this field. Learn more about the [special configuration options for training with TPUs](/ai-platform/training/docs/using-tpus#configuring_a_custom_tpu_machine).
     * 
     */
    @Import(name="masterType")
    private @Nullable Output<String> masterType;

    /**
     * @return Optional. Specifies the type of virtual machine to use for your training job&#39;s master worker. You must specify this field when `scaleTier` is set to `CUSTOM`. You can use certain Compute Engine machine types directly in this field. See the [list of compatible Compute Engine machine types](/ai-platform/training/docs/machine-types#compute-engine-machine-types). Alternatively, you can use the certain legacy machine types in this field. See the [list of legacy machine types](/ai-platform/training/docs/machine-types#legacy-machine-types). Finally, if you want to use a TPU for training, specify `cloud_tpu` in this field. Learn more about the [special configuration options for training with TPUs](/ai-platform/training/docs/using-tpus#configuring_a_custom_tpu_machine).
     * 
     */
    public Optional<Output<String>> masterType() {
        return Optional.ofNullable(this.masterType);
    }

    /**
     * Optional. The full name of the [Compute Engine network](/vpc/docs/vpc) to which the Job is peered. For example, `projects/12345/global/networks/myVPC`. The format of this field is `projects/{project}/global/networks/{network}`, where {project} is a project number (like `12345`) and {network} is network name. Private services access must already be configured for the network. If left unspecified, the Job is not peered with any network. [Learn about using VPC Network Peering.](/ai-platform/training/docs/vpc-peering).
     * 
     */
    @Import(name="network")
    private @Nullable Output<String> network;

    /**
     * @return Optional. The full name of the [Compute Engine network](/vpc/docs/vpc) to which the Job is peered. For example, `projects/12345/global/networks/myVPC`. The format of this field is `projects/{project}/global/networks/{network}`, where {project} is a project number (like `12345`) and {network} is network name. Private services access must already be configured for the network. If left unspecified, the Job is not peered with any network. [Learn about using VPC Network Peering.](/ai-platform/training/docs/vpc-peering).
     * 
     */
    public Optional<Output<String>> network() {
        return Optional.ofNullable(this.network);
    }

    /**
     * The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100.
     * 
     */
    @Import(name="packageUris", required=true)
    private Output<List<String>> packageUris;

    /**
     * @return The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100.
     * 
     */
    public Output<List<String>> packageUris() {
        return this.packageUris;
    }

    /**
     * Optional. The configuration for parameter servers. You should only set `parameterServerConfig.acceleratorConfig` if `parameterServerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `parameterServerConfig.imageUri` only if you build a custom image for your parameter server. If `parameterServerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
     * 
     */
    @Import(name="parameterServerConfig")
    private @Nullable Output<GoogleCloudMlV1__ReplicaConfigArgs> parameterServerConfig;

    /**
     * @return Optional. The configuration for parameter servers. You should only set `parameterServerConfig.acceleratorConfig` if `parameterServerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `parameterServerConfig.imageUri` only if you build a custom image for your parameter server. If `parameterServerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
     * 
     */
    public Optional<Output<GoogleCloudMlV1__ReplicaConfigArgs>> parameterServerConfig() {
        return Optional.ofNullable(this.parameterServerConfig);
    }

    /**
     * Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in `parameter_server_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `parameter_server_type`. The default value is zero.
     * 
     */
    @Import(name="parameterServerCount")
    private @Nullable Output<String> parameterServerCount;

    /**
     * @return Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in `parameter_server_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `parameter_server_type`. The default value is zero.
     * 
     */
    public Optional<Output<String>> parameterServerCount() {
        return Optional.ofNullable(this.parameterServerCount);
    }

    /**
     * Optional. Specifies the type of virtual machine to use for your training job&#39;s parameter server. The supported values are the same as those described in the entry for `master_type`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `parameter_server_count` is greater than zero.
     * 
     */
    @Import(name="parameterServerType")
    private @Nullable Output<String> parameterServerType;

    /**
     * @return Optional. Specifies the type of virtual machine to use for your training job&#39;s parameter server. The supported values are the same as those described in the entry for `master_type`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `parameter_server_count` is greater than zero.
     * 
     */
    public Optional<Output<String>> parameterServerType() {
        return Optional.ofNullable(this.parameterServerType);
    }

    /**
     * The Python module name to run after installing the packages.
     * 
     */
    @Import(name="pythonModule", required=true)
    private Output<String> pythonModule;

    /**
     * @return The Python module name to run after installing the packages.
     * 
     */
    public Output<String> pythonModule() {
        return this.pythonModule;
    }

    /**
     * Optional. The version of Python used in training. You must either specify this field or specify `masterConfig.imageUri`. The following Python versions are available: * Python &#39;3.7&#39; is available when `runtime_version` is set to &#39;1.15&#39; or later. * Python &#39;3.5&#39; is available when `runtime_version` is set to a version from &#39;1.4&#39; to &#39;1.14&#39;. * Python &#39;2.7&#39; is available when `runtime_version` is set to &#39;1.15&#39; or earlier. Read more about the Python versions available for [each runtime version](/ml-engine/docs/runtime-version-list).
     * 
     */
    @Import(name="pythonVersion")
    private @Nullable Output<String> pythonVersion;

    /**
     * @return Optional. The version of Python used in training. You must either specify this field or specify `masterConfig.imageUri`. The following Python versions are available: * Python &#39;3.7&#39; is available when `runtime_version` is set to &#39;1.15&#39; or later. * Python &#39;3.5&#39; is available when `runtime_version` is set to a version from &#39;1.4&#39; to &#39;1.14&#39;. * Python &#39;2.7&#39; is available when `runtime_version` is set to &#39;1.15&#39; or earlier. Read more about the Python versions available for [each runtime version](/ml-engine/docs/runtime-version-list).
     * 
     */
    public Optional<Output<String>> pythonVersion() {
        return Optional.ofNullable(this.pythonVersion);
    }

    /**
     * The region to run the training job in. See the [available regions](/ai-platform/training/docs/regions) for AI Platform Training.
     * 
     */
    @Import(name="region", required=true)
    private Output<String> region;

    /**
     * @return The region to run the training job in. See the [available regions](/ai-platform/training/docs/regions) for AI Platform Training.
     * 
     */
    public Output<String> region() {
        return this.region;
    }

    /**
     * Optional. The AI Platform runtime version to use for training. You must either specify this field or specify `masterConfig.imageUri`. For more information, see the [runtime version list](/ai-platform/training/docs/runtime-version-list) and learn [how to manage runtime versions](/ai-platform/training/docs/versioning).
     * 
     */
    @Import(name="runtimeVersion")
    private @Nullable Output<String> runtimeVersion;

    /**
     * @return Optional. The AI Platform runtime version to use for training. You must either specify this field or specify `masterConfig.imageUri`. For more information, see the [runtime version list](/ai-platform/training/docs/runtime-version-list) and learn [how to manage runtime versions](/ai-platform/training/docs/versioning).
     * 
     */
    public Optional<Output<String>> runtimeVersion() {
        return Optional.ofNullable(this.runtimeVersion);
    }

    /**
     * Specifies the machine types, the number of replicas for workers and parameter servers.
     * 
     */
    @Import(name="scaleTier", required=true)
    private Output<GoogleCloudMlV1__TrainingInputScaleTier> scaleTier;

    /**
     * @return Specifies the machine types, the number of replicas for workers and parameter servers.
     * 
     */
    public Output<GoogleCloudMlV1__TrainingInputScaleTier> scaleTier() {
        return this.scaleTier;
    }

    /**
     * Optional. Scheduling options for a training job.
     * 
     */
    @Import(name="scheduling")
    private @Nullable Output<GoogleCloudMlV1__SchedulingArgs> scheduling;

    /**
     * @return Optional. Scheduling options for a training job.
     * 
     */
    public Optional<Output<GoogleCloudMlV1__SchedulingArgs>> scheduling() {
        return Optional.ofNullable(this.scheduling);
    }

    /**
     * Optional. The email address of a service account to use when running the training appplication. You must have the `iam.serviceAccounts.actAs` permission for the specified service account. In addition, the AI Platform Training Google-managed service account must have the `roles/iam.serviceAccountAdmin` role for the specified service account. [Learn more about configuring a service account.](/ai-platform/training/docs/custom-service-account) If not specified, the AI Platform Training Google-managed service account is used by default.
     * 
     */
    @Import(name="serviceAccount")
    private @Nullable Output<String> serviceAccount;

    /**
     * @return Optional. The email address of a service account to use when running the training appplication. You must have the `iam.serviceAccounts.actAs` permission for the specified service account. In addition, the AI Platform Training Google-managed service account must have the `roles/iam.serviceAccountAdmin` role for the specified service account. [Learn more about configuring a service account.](/ai-platform/training/docs/custom-service-account) If not specified, the AI Platform Training Google-managed service account is used by default.
     * 
     */
    public Optional<Output<String>> serviceAccount() {
        return Optional.ofNullable(this.serviceAccount);
    }

    /**
     * Optional. Use `chief` instead of `master` in the `TF_CONFIG` environment variable when training with a custom container. Defaults to `false`. [Learn more about this field.](/ai-platform/training/docs/distributed-training-details#chief-versus-master) This field has no effect for training jobs that don&#39;t use a custom container.
     * 
     */
    @Import(name="useChiefInTfConfig")
    private @Nullable Output<Boolean> useChiefInTfConfig;

    /**
     * @return Optional. Use `chief` instead of `master` in the `TF_CONFIG` environment variable when training with a custom container. Defaults to `false`. [Learn more about this field.](/ai-platform/training/docs/distributed-training-details#chief-versus-master) This field has no effect for training jobs that don&#39;t use a custom container.
     * 
     */
    public Optional<Output<Boolean>> useChiefInTfConfig() {
        return Optional.ofNullable(this.useChiefInTfConfig);
    }

    /**
     * Optional. The configuration for workers. You should only set `workerConfig.acceleratorConfig` if `workerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `workerConfig.imageUri` only if you build a custom image for your worker. If `workerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
     * 
     */
    @Import(name="workerConfig")
    private @Nullable Output<GoogleCloudMlV1__ReplicaConfigArgs> workerConfig;

    /**
     * @return Optional. The configuration for workers. You should only set `workerConfig.acceleratorConfig` if `workerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `workerConfig.imageUri` only if you build a custom image for your worker. If `workerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
     * 
     */
    public Optional<Output<GoogleCloudMlV1__ReplicaConfigArgs>> workerConfig() {
        return Optional.ofNullable(this.workerConfig);
    }

    /**
     * Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in `worker_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `worker_type`. The default value is zero.
     * 
     */
    @Import(name="workerCount")
    private @Nullable Output<String> workerCount;

    /**
     * @return Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in `worker_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `worker_type`. The default value is zero.
     * 
     */
    public Optional<Output<String>> workerCount() {
        return Optional.ofNullable(this.workerCount);
    }

    /**
     * Optional. Specifies the type of virtual machine to use for your training job&#39;s worker nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. If you use `cloud_tpu` for this value, see special instructions for [configuring a custom TPU machine](/ml-engine/docs/tensorflow/using-tpus#configuring_a_custom_tpu_machine). This value must be present when `scaleTier` is set to `CUSTOM` and `workerCount` is greater than zero.
     * 
     */
    @Import(name="workerType")
    private @Nullable Output<String> workerType;

    /**
     * @return Optional. Specifies the type of virtual machine to use for your training job&#39;s worker nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. If you use `cloud_tpu` for this value, see special instructions for [configuring a custom TPU machine](/ml-engine/docs/tensorflow/using-tpus#configuring_a_custom_tpu_machine). This value must be present when `scaleTier` is set to `CUSTOM` and `workerCount` is greater than zero.
     * 
     */
    public Optional<Output<String>> workerType() {
        return Optional.ofNullable(this.workerType);
    }

    private GoogleCloudMlV1__TrainingInputArgs() {}

    private GoogleCloudMlV1__TrainingInputArgs(GoogleCloudMlV1__TrainingInputArgs $) {
        this.args = $.args;
        this.enableWebAccess = $.enableWebAccess;
        this.encryptionConfig = $.encryptionConfig;
        this.evaluatorConfig = $.evaluatorConfig;
        this.evaluatorCount = $.evaluatorCount;
        this.evaluatorType = $.evaluatorType;
        this.hyperparameters = $.hyperparameters;
        this.jobDir = $.jobDir;
        this.masterConfig = $.masterConfig;
        this.masterType = $.masterType;
        this.network = $.network;
        this.packageUris = $.packageUris;
        this.parameterServerConfig = $.parameterServerConfig;
        this.parameterServerCount = $.parameterServerCount;
        this.parameterServerType = $.parameterServerType;
        this.pythonModule = $.pythonModule;
        this.pythonVersion = $.pythonVersion;
        this.region = $.region;
        this.runtimeVersion = $.runtimeVersion;
        this.scaleTier = $.scaleTier;
        this.scheduling = $.scheduling;
        this.serviceAccount = $.serviceAccount;
        this.useChiefInTfConfig = $.useChiefInTfConfig;
        this.workerConfig = $.workerConfig;
        this.workerCount = $.workerCount;
        this.workerType = $.workerType;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(GoogleCloudMlV1__TrainingInputArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private GoogleCloudMlV1__TrainingInputArgs $;

        public Builder() {
            $ = new GoogleCloudMlV1__TrainingInputArgs();
        }

        public Builder(GoogleCloudMlV1__TrainingInputArgs defaults) {
            $ = new GoogleCloudMlV1__TrainingInputArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param args Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container&#39;s `ENTRYPOINT` command.
         * 
         * @return builder
         * 
         */
        public Builder args(@Nullable Output<List<String>> args) {
            $.args = args;
            return this;
        }

        /**
         * @param args Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container&#39;s `ENTRYPOINT` command.
         * 
         * @return builder
         * 
         */
        public Builder args(List<String> args) {
            return args(Output.of(args));
        }

        /**
         * @param args Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container&#39;s `ENTRYPOINT` command.
         * 
         * @return builder
         * 
         */
        public Builder args(String... args) {
            return args(List.of(args));
        }

        /**
         * @param enableWebAccess Optional. Whether you want AI Platform Training to enable [interactive shell access](https://cloud.google.com/ai-platform/training/docs/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by TrainingOutput.web_access_uris or HyperparameterOutput.web_access_uris (within TrainingOutput.trials).
         * 
         * @return builder
         * 
         */
        public Builder enableWebAccess(@Nullable Output<Boolean> enableWebAccess) {
            $.enableWebAccess = enableWebAccess;
            return this;
        }

        /**
         * @param enableWebAccess Optional. Whether you want AI Platform Training to enable [interactive shell access](https://cloud.google.com/ai-platform/training/docs/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by TrainingOutput.web_access_uris or HyperparameterOutput.web_access_uris (within TrainingOutput.trials).
         * 
         * @return builder
         * 
         */
        public Builder enableWebAccess(Boolean enableWebAccess) {
            return enableWebAccess(Output.of(enableWebAccess));
        }

        /**
         * @param encryptionConfig Optional. Options for using customer-managed encryption keys (CMEK) to protect resources created by a training job, instead of using Google&#39;s default encryption. If this is set, then all resources created by the training job will be encrypted with the customer-managed encryption key that you specify. [Learn how and when to use CMEK with AI Platform Training](/ai-platform/training/docs/cmek).
         * 
         * @return builder
         * 
         */
        public Builder encryptionConfig(@Nullable Output<GoogleCloudMlV1__EncryptionConfigArgs> encryptionConfig) {
            $.encryptionConfig = encryptionConfig;
            return this;
        }

        /**
         * @param encryptionConfig Optional. Options for using customer-managed encryption keys (CMEK) to protect resources created by a training job, instead of using Google&#39;s default encryption. If this is set, then all resources created by the training job will be encrypted with the customer-managed encryption key that you specify. [Learn how and when to use CMEK with AI Platform Training](/ai-platform/training/docs/cmek).
         * 
         * @return builder
         * 
         */
        public Builder encryptionConfig(GoogleCloudMlV1__EncryptionConfigArgs encryptionConfig) {
            return encryptionConfig(Output.of(encryptionConfig));
        }

        /**
         * @param evaluatorConfig Optional. The configuration for evaluators. You should only set `evaluatorConfig.acceleratorConfig` if `evaluatorType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `evaluatorConfig.imageUri` only if you build a custom image for your evaluator. If `evaluatorConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
         * 
         * @return builder
         * 
         */
        public Builder evaluatorConfig(@Nullable Output<GoogleCloudMlV1__ReplicaConfigArgs> evaluatorConfig) {
            $.evaluatorConfig = evaluatorConfig;
            return this;
        }

        /**
         * @param evaluatorConfig Optional. The configuration for evaluators. You should only set `evaluatorConfig.acceleratorConfig` if `evaluatorType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `evaluatorConfig.imageUri` only if you build a custom image for your evaluator. If `evaluatorConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
         * 
         * @return builder
         * 
         */
        public Builder evaluatorConfig(GoogleCloudMlV1__ReplicaConfigArgs evaluatorConfig) {
            return evaluatorConfig(Output.of(evaluatorConfig));
        }

        /**
         * @param evaluatorCount Optional. The number of evaluator replicas to use for the training job. Each replica in the cluster will be of the type specified in `evaluator_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `evaluator_type`. The default value is zero.
         * 
         * @return builder
         * 
         */
        public Builder evaluatorCount(@Nullable Output<String> evaluatorCount) {
            $.evaluatorCount = evaluatorCount;
            return this;
        }

        /**
         * @param evaluatorCount Optional. The number of evaluator replicas to use for the training job. Each replica in the cluster will be of the type specified in `evaluator_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `evaluator_type`. The default value is zero.
         * 
         * @return builder
         * 
         */
        public Builder evaluatorCount(String evaluatorCount) {
            return evaluatorCount(Output.of(evaluatorCount));
        }

        /**
         * @param evaluatorType Optional. Specifies the type of virtual machine to use for your training job&#39;s evaluator nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `evaluatorCount` is greater than zero.
         * 
         * @return builder
         * 
         */
        public Builder evaluatorType(@Nullable Output<String> evaluatorType) {
            $.evaluatorType = evaluatorType;
            return this;
        }

        /**
         * @param evaluatorType Optional. Specifies the type of virtual machine to use for your training job&#39;s evaluator nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `evaluatorCount` is greater than zero.
         * 
         * @return builder
         * 
         */
        public Builder evaluatorType(String evaluatorType) {
            return evaluatorType(Output.of(evaluatorType));
        }

        /**
         * @param hyperparameters Optional. The set of Hyperparameters to tune.
         * 
         * @return builder
         * 
         */
        public Builder hyperparameters(@Nullable Output<GoogleCloudMlV1__HyperparameterSpecArgs> hyperparameters) {
            $.hyperparameters = hyperparameters;
            return this;
        }

        /**
         * @param hyperparameters Optional. The set of Hyperparameters to tune.
         * 
         * @return builder
         * 
         */
        public Builder hyperparameters(GoogleCloudMlV1__HyperparameterSpecArgs hyperparameters) {
            return hyperparameters(Output.of(hyperparameters));
        }

        /**
         * @param jobDir Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the &#39;--job-dir&#39; command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training.
         * 
         * @return builder
         * 
         */
        public Builder jobDir(@Nullable Output<String> jobDir) {
            $.jobDir = jobDir;
            return this;
        }

        /**
         * @param jobDir Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the &#39;--job-dir&#39; command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training.
         * 
         * @return builder
         * 
         */
        public Builder jobDir(String jobDir) {
            return jobDir(Output.of(jobDir));
        }

        /**
         * @param masterConfig Optional. The configuration for your master worker. You should only set `masterConfig.acceleratorConfig` if `masterType` is set to a Compute Engine machine type. Learn about [restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `masterConfig.imageUri` only if you build a custom image. Only one of `masterConfig.imageUri` and `runtimeVersion` should be set. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
         * 
         * @return builder
         * 
         */
        public Builder masterConfig(@Nullable Output<GoogleCloudMlV1__ReplicaConfigArgs> masterConfig) {
            $.masterConfig = masterConfig;
            return this;
        }

        /**
         * @param masterConfig Optional. The configuration for your master worker. You should only set `masterConfig.acceleratorConfig` if `masterType` is set to a Compute Engine machine type. Learn about [restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `masterConfig.imageUri` only if you build a custom image. Only one of `masterConfig.imageUri` and `runtimeVersion` should be set. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
         * 
         * @return builder
         * 
         */
        public Builder masterConfig(GoogleCloudMlV1__ReplicaConfigArgs masterConfig) {
            return masterConfig(Output.of(masterConfig));
        }

        /**
         * @param masterType Optional. Specifies the type of virtual machine to use for your training job&#39;s master worker. You must specify this field when `scaleTier` is set to `CUSTOM`. You can use certain Compute Engine machine types directly in this field. See the [list of compatible Compute Engine machine types](/ai-platform/training/docs/machine-types#compute-engine-machine-types). Alternatively, you can use the certain legacy machine types in this field. See the [list of legacy machine types](/ai-platform/training/docs/machine-types#legacy-machine-types). Finally, if you want to use a TPU for training, specify `cloud_tpu` in this field. Learn more about the [special configuration options for training with TPUs](/ai-platform/training/docs/using-tpus#configuring_a_custom_tpu_machine).
         * 
         * @return builder
         * 
         */
        public Builder masterType(@Nullable Output<String> masterType) {
            $.masterType = masterType;
            return this;
        }

        /**
         * @param masterType Optional. Specifies the type of virtual machine to use for your training job&#39;s master worker. You must specify this field when `scaleTier` is set to `CUSTOM`. You can use certain Compute Engine machine types directly in this field. See the [list of compatible Compute Engine machine types](/ai-platform/training/docs/machine-types#compute-engine-machine-types). Alternatively, you can use the certain legacy machine types in this field. See the [list of legacy machine types](/ai-platform/training/docs/machine-types#legacy-machine-types). Finally, if you want to use a TPU for training, specify `cloud_tpu` in this field. Learn more about the [special configuration options for training with TPUs](/ai-platform/training/docs/using-tpus#configuring_a_custom_tpu_machine).
         * 
         * @return builder
         * 
         */
        public Builder masterType(String masterType) {
            return masterType(Output.of(masterType));
        }

        /**
         * @param network Optional. The full name of the [Compute Engine network](/vpc/docs/vpc) to which the Job is peered. For example, `projects/12345/global/networks/myVPC`. The format of this field is `projects/{project}/global/networks/{network}`, where {project} is a project number (like `12345`) and {network} is network name. Private services access must already be configured for the network. If left unspecified, the Job is not peered with any network. [Learn about using VPC Network Peering.](/ai-platform/training/docs/vpc-peering).
         * 
         * @return builder
         * 
         */
        public Builder network(@Nullable Output<String> network) {
            $.network = network;
            return this;
        }

        /**
         * @param network Optional. The full name of the [Compute Engine network](/vpc/docs/vpc) to which the Job is peered. For example, `projects/12345/global/networks/myVPC`. The format of this field is `projects/{project}/global/networks/{network}`, where {project} is a project number (like `12345`) and {network} is network name. Private services access must already be configured for the network. If left unspecified, the Job is not peered with any network. [Learn about using VPC Network Peering.](/ai-platform/training/docs/vpc-peering).
         * 
         * @return builder
         * 
         */
        public Builder network(String network) {
            return network(Output.of(network));
        }

        /**
         * @param packageUris The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100.
         * 
         * @return builder
         * 
         */
        public Builder packageUris(Output<List<String>> packageUris) {
            $.packageUris = packageUris;
            return this;
        }

        /**
         * @param packageUris The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100.
         * 
         * @return builder
         * 
         */
        public Builder packageUris(List<String> packageUris) {
            return packageUris(Output.of(packageUris));
        }

        /**
         * @param packageUris The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100.
         * 
         * @return builder
         * 
         */
        public Builder packageUris(String... packageUris) {
            return packageUris(List.of(packageUris));
        }

        /**
         * @param parameterServerConfig Optional. The configuration for parameter servers. You should only set `parameterServerConfig.acceleratorConfig` if `parameterServerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `parameterServerConfig.imageUri` only if you build a custom image for your parameter server. If `parameterServerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
         * 
         * @return builder
         * 
         */
        public Builder parameterServerConfig(@Nullable Output<GoogleCloudMlV1__ReplicaConfigArgs> parameterServerConfig) {
            $.parameterServerConfig = parameterServerConfig;
            return this;
        }

        /**
         * @param parameterServerConfig Optional. The configuration for parameter servers. You should only set `parameterServerConfig.acceleratorConfig` if `parameterServerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `parameterServerConfig.imageUri` only if you build a custom image for your parameter server. If `parameterServerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
         * 
         * @return builder
         * 
         */
        public Builder parameterServerConfig(GoogleCloudMlV1__ReplicaConfigArgs parameterServerConfig) {
            return parameterServerConfig(Output.of(parameterServerConfig));
        }

        /**
         * @param parameterServerCount Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in `parameter_server_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `parameter_server_type`. The default value is zero.
         * 
         * @return builder
         * 
         */
        public Builder parameterServerCount(@Nullable Output<String> parameterServerCount) {
            $.parameterServerCount = parameterServerCount;
            return this;
        }

        /**
         * @param parameterServerCount Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in `parameter_server_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `parameter_server_type`. The default value is zero.
         * 
         * @return builder
         * 
         */
        public Builder parameterServerCount(String parameterServerCount) {
            return parameterServerCount(Output.of(parameterServerCount));
        }

        /**
         * @param parameterServerType Optional. Specifies the type of virtual machine to use for your training job&#39;s parameter server. The supported values are the same as those described in the entry for `master_type`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `parameter_server_count` is greater than zero.
         * 
         * @return builder
         * 
         */
        public Builder parameterServerType(@Nullable Output<String> parameterServerType) {
            $.parameterServerType = parameterServerType;
            return this;
        }

        /**
         * @param parameterServerType Optional. Specifies the type of virtual machine to use for your training job&#39;s parameter server. The supported values are the same as those described in the entry for `master_type`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `parameter_server_count` is greater than zero.
         * 
         * @return builder
         * 
         */
        public Builder parameterServerType(String parameterServerType) {
            return parameterServerType(Output.of(parameterServerType));
        }

        /**
         * @param pythonModule The Python module name to run after installing the packages.
         * 
         * @return builder
         * 
         */
        public Builder pythonModule(Output<String> pythonModule) {
            $.pythonModule = pythonModule;
            return this;
        }

        /**
         * @param pythonModule The Python module name to run after installing the packages.
         * 
         * @return builder
         * 
         */
        public Builder pythonModule(String pythonModule) {
            return pythonModule(Output.of(pythonModule));
        }

        /**
         * @param pythonVersion Optional. The version of Python used in training. You must either specify this field or specify `masterConfig.imageUri`. The following Python versions are available: * Python &#39;3.7&#39; is available when `runtime_version` is set to &#39;1.15&#39; or later. * Python &#39;3.5&#39; is available when `runtime_version` is set to a version from &#39;1.4&#39; to &#39;1.14&#39;. * Python &#39;2.7&#39; is available when `runtime_version` is set to &#39;1.15&#39; or earlier. Read more about the Python versions available for [each runtime version](/ml-engine/docs/runtime-version-list).
         * 
         * @return builder
         * 
         */
        public Builder pythonVersion(@Nullable Output<String> pythonVersion) {
            $.pythonVersion = pythonVersion;
            return this;
        }

        /**
         * @param pythonVersion Optional. The version of Python used in training. You must either specify this field or specify `masterConfig.imageUri`. The following Python versions are available: * Python &#39;3.7&#39; is available when `runtime_version` is set to &#39;1.15&#39; or later. * Python &#39;3.5&#39; is available when `runtime_version` is set to a version from &#39;1.4&#39; to &#39;1.14&#39;. * Python &#39;2.7&#39; is available when `runtime_version` is set to &#39;1.15&#39; or earlier. Read more about the Python versions available for [each runtime version](/ml-engine/docs/runtime-version-list).
         * 
         * @return builder
         * 
         */
        public Builder pythonVersion(String pythonVersion) {
            return pythonVersion(Output.of(pythonVersion));
        }

        /**
         * @param region The region to run the training job in. See the [available regions](/ai-platform/training/docs/regions) for AI Platform Training.
         * 
         * @return builder
         * 
         */
        public Builder region(Output<String> region) {
            $.region = region;
            return this;
        }

        /**
         * @param region The region to run the training job in. See the [available regions](/ai-platform/training/docs/regions) for AI Platform Training.
         * 
         * @return builder
         * 
         */
        public Builder region(String region) {
            return region(Output.of(region));
        }

        /**
         * @param runtimeVersion Optional. The AI Platform runtime version to use for training. You must either specify this field or specify `masterConfig.imageUri`. For more information, see the [runtime version list](/ai-platform/training/docs/runtime-version-list) and learn [how to manage runtime versions](/ai-platform/training/docs/versioning).
         * 
         * @return builder
         * 
         */
        public Builder runtimeVersion(@Nullable Output<String> runtimeVersion) {
            $.runtimeVersion = runtimeVersion;
            return this;
        }

        /**
         * @param runtimeVersion Optional. The AI Platform runtime version to use for training. You must either specify this field or specify `masterConfig.imageUri`. For more information, see the [runtime version list](/ai-platform/training/docs/runtime-version-list) and learn [how to manage runtime versions](/ai-platform/training/docs/versioning).
         * 
         * @return builder
         * 
         */
        public Builder runtimeVersion(String runtimeVersion) {
            return runtimeVersion(Output.of(runtimeVersion));
        }

        /**
         * @param scaleTier Specifies the machine types, the number of replicas for workers and parameter servers.
         * 
         * @return builder
         * 
         */
        public Builder scaleTier(Output<GoogleCloudMlV1__TrainingInputScaleTier> scaleTier) {
            $.scaleTier = scaleTier;
            return this;
        }

        /**
         * @param scaleTier Specifies the machine types, the number of replicas for workers and parameter servers.
         * 
         * @return builder
         * 
         */
        public Builder scaleTier(GoogleCloudMlV1__TrainingInputScaleTier scaleTier) {
            return scaleTier(Output.of(scaleTier));
        }

        /**
         * @param scheduling Optional. Scheduling options for a training job.
         * 
         * @return builder
         * 
         */
        public Builder scheduling(@Nullable Output<GoogleCloudMlV1__SchedulingArgs> scheduling) {
            $.scheduling = scheduling;
            return this;
        }

        /**
         * @param scheduling Optional. Scheduling options for a training job.
         * 
         * @return builder
         * 
         */
        public Builder scheduling(GoogleCloudMlV1__SchedulingArgs scheduling) {
            return scheduling(Output.of(scheduling));
        }

        /**
         * @param serviceAccount Optional. The email address of a service account to use when running the training appplication. You must have the `iam.serviceAccounts.actAs` permission for the specified service account. In addition, the AI Platform Training Google-managed service account must have the `roles/iam.serviceAccountAdmin` role for the specified service account. [Learn more about configuring a service account.](/ai-platform/training/docs/custom-service-account) If not specified, the AI Platform Training Google-managed service account is used by default.
         * 
         * @return builder
         * 
         */
        public Builder serviceAccount(@Nullable Output<String> serviceAccount) {
            $.serviceAccount = serviceAccount;
            return this;
        }

        /**
         * @param serviceAccount Optional. The email address of a service account to use when running the training appplication. You must have the `iam.serviceAccounts.actAs` permission for the specified service account. In addition, the AI Platform Training Google-managed service account must have the `roles/iam.serviceAccountAdmin` role for the specified service account. [Learn more about configuring a service account.](/ai-platform/training/docs/custom-service-account) If not specified, the AI Platform Training Google-managed service account is used by default.
         * 
         * @return builder
         * 
         */
        public Builder serviceAccount(String serviceAccount) {
            return serviceAccount(Output.of(serviceAccount));
        }

        /**
         * @param useChiefInTfConfig Optional. Use `chief` instead of `master` in the `TF_CONFIG` environment variable when training with a custom container. Defaults to `false`. [Learn more about this field.](/ai-platform/training/docs/distributed-training-details#chief-versus-master) This field has no effect for training jobs that don&#39;t use a custom container.
         * 
         * @return builder
         * 
         */
        public Builder useChiefInTfConfig(@Nullable Output<Boolean> useChiefInTfConfig) {
            $.useChiefInTfConfig = useChiefInTfConfig;
            return this;
        }

        /**
         * @param useChiefInTfConfig Optional. Use `chief` instead of `master` in the `TF_CONFIG` environment variable when training with a custom container. Defaults to `false`. [Learn more about this field.](/ai-platform/training/docs/distributed-training-details#chief-versus-master) This field has no effect for training jobs that don&#39;t use a custom container.
         * 
         * @return builder
         * 
         */
        public Builder useChiefInTfConfig(Boolean useChiefInTfConfig) {
            return useChiefInTfConfig(Output.of(useChiefInTfConfig));
        }

        /**
         * @param workerConfig Optional. The configuration for workers. You should only set `workerConfig.acceleratorConfig` if `workerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `workerConfig.imageUri` only if you build a custom image for your worker. If `workerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
         * 
         * @return builder
         * 
         */
        public Builder workerConfig(@Nullable Output<GoogleCloudMlV1__ReplicaConfigArgs> workerConfig) {
            $.workerConfig = workerConfig;
            return this;
        }

        /**
         * @param workerConfig Optional. The configuration for workers. You should only set `workerConfig.acceleratorConfig` if `workerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `workerConfig.imageUri` only if you build a custom image for your worker. If `workerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
         * 
         * @return builder
         * 
         */
        public Builder workerConfig(GoogleCloudMlV1__ReplicaConfigArgs workerConfig) {
            return workerConfig(Output.of(workerConfig));
        }

        /**
         * @param workerCount Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in `worker_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `worker_type`. The default value is zero.
         * 
         * @return builder
         * 
         */
        public Builder workerCount(@Nullable Output<String> workerCount) {
            $.workerCount = workerCount;
            return this;
        }

        /**
         * @param workerCount Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in `worker_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `worker_type`. The default value is zero.
         * 
         * @return builder
         * 
         */
        public Builder workerCount(String workerCount) {
            return workerCount(Output.of(workerCount));
        }

        /**
         * @param workerType Optional. Specifies the type of virtual machine to use for your training job&#39;s worker nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. If you use `cloud_tpu` for this value, see special instructions for [configuring a custom TPU machine](/ml-engine/docs/tensorflow/using-tpus#configuring_a_custom_tpu_machine). This value must be present when `scaleTier` is set to `CUSTOM` and `workerCount` is greater than zero.
         * 
         * @return builder
         * 
         */
        public Builder workerType(@Nullable Output<String> workerType) {
            $.workerType = workerType;
            return this;
        }

        /**
         * @param workerType Optional. Specifies the type of virtual machine to use for your training job&#39;s worker nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. If you use `cloud_tpu` for this value, see special instructions for [configuring a custom TPU machine](/ml-engine/docs/tensorflow/using-tpus#configuring_a_custom_tpu_machine). This value must be present when `scaleTier` is set to `CUSTOM` and `workerCount` is greater than zero.
         * 
         * @return builder
         * 
         */
        public Builder workerType(String workerType) {
            return workerType(Output.of(workerType));
        }

        public GoogleCloudMlV1__TrainingInputArgs build() {
            $.packageUris = Objects.requireNonNull($.packageUris, "expected parameter 'packageUris' to be non-null");
            $.pythonModule = Objects.requireNonNull($.pythonModule, "expected parameter 'pythonModule' to be non-null");
            $.region = Objects.requireNonNull($.region, "expected parameter 'region' to be non-null");
            $.scaleTier = Objects.requireNonNull($.scaleTier, "expected parameter 'scaleTier' to be non-null");
            return $;
        }
    }

}
