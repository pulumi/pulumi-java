// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.googlenative.dataproc.v1;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.googlenative.dataproc.v1.inputs.HadoopJobArgs;
import com.pulumi.googlenative.dataproc.v1.inputs.HiveJobArgs;
import com.pulumi.googlenative.dataproc.v1.inputs.JobPlacementArgs;
import com.pulumi.googlenative.dataproc.v1.inputs.JobReferenceArgs;
import com.pulumi.googlenative.dataproc.v1.inputs.JobSchedulingArgs;
import com.pulumi.googlenative.dataproc.v1.inputs.PigJobArgs;
import com.pulumi.googlenative.dataproc.v1.inputs.PrestoJobArgs;
import com.pulumi.googlenative.dataproc.v1.inputs.PySparkJobArgs;
import com.pulumi.googlenative.dataproc.v1.inputs.SparkJobArgs;
import com.pulumi.googlenative.dataproc.v1.inputs.SparkRJobArgs;
import com.pulumi.googlenative.dataproc.v1.inputs.SparkSqlJobArgs;
import java.lang.String;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class JobArgs extends com.pulumi.resources.ResourceArgs {

    public static final JobArgs Empty = new JobArgs();

    /**
     * Optional. Job is a Hadoop job.
     * 
     */
    @Import(name="hadoopJob")
    private @Nullable Output<HadoopJobArgs> hadoopJob;

    /**
     * @return Optional. Job is a Hadoop job.
     * 
     */
    public Optional<Output<HadoopJobArgs>> hadoopJob() {
        return Optional.ofNullable(this.hadoopJob);
    }

    /**
     * Optional. Job is a Hive job.
     * 
     */
    @Import(name="hiveJob")
    private @Nullable Output<HiveJobArgs> hiveJob;

    /**
     * @return Optional. Job is a Hive job.
     * 
     */
    public Optional<Output<HiveJobArgs>> hiveJob() {
        return Optional.ofNullable(this.hiveJob);
    }

    /**
     * Optional. The labels to associate with this job. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a job.
     * 
     */
    @Import(name="labels")
    private @Nullable Output<Map<String,String>> labels;

    /**
     * @return Optional. The labels to associate with this job. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a job.
     * 
     */
    public Optional<Output<Map<String,String>>> labels() {
        return Optional.ofNullable(this.labels);
    }

    /**
     * Optional. Job is a Pig job.
     * 
     */
    @Import(name="pigJob")
    private @Nullable Output<PigJobArgs> pigJob;

    /**
     * @return Optional. Job is a Pig job.
     * 
     */
    public Optional<Output<PigJobArgs>> pigJob() {
        return Optional.ofNullable(this.pigJob);
    }

    /**
     * Job information, including how, when, and where to run the job.
     * 
     */
    @Import(name="placement", required=true)
    private Output<JobPlacementArgs> placement;

    /**
     * @return Job information, including how, when, and where to run the job.
     * 
     */
    public Output<JobPlacementArgs> placement() {
        return this.placement;
    }

    /**
     * Optional. Job is a Presto job.
     * 
     */
    @Import(name="prestoJob")
    private @Nullable Output<PrestoJobArgs> prestoJob;

    /**
     * @return Optional. Job is a Presto job.
     * 
     */
    public Optional<Output<PrestoJobArgs>> prestoJob() {
        return Optional.ofNullable(this.prestoJob);
    }

    @Import(name="project")
    private @Nullable Output<String> project;

    public Optional<Output<String>> project() {
        return Optional.ofNullable(this.project);
    }

    /**
     * Optional. Job is a PySpark job.
     * 
     */
    @Import(name="pysparkJob")
    private @Nullable Output<PySparkJobArgs> pysparkJob;

    /**
     * @return Optional. Job is a PySpark job.
     * 
     */
    public Optional<Output<PySparkJobArgs>> pysparkJob() {
        return Optional.ofNullable(this.pysparkJob);
    }

    /**
     * Optional. The fully qualified reference to the job, which can be used to obtain the equivalent REST path of the job resource. If this property is not specified when a job is created, the server generates a job_id.
     * 
     */
    @Import(name="reference")
    private @Nullable Output<JobReferenceArgs> reference;

    /**
     * @return Optional. The fully qualified reference to the job, which can be used to obtain the equivalent REST path of the job resource. If this property is not specified when a job is created, the server generates a job_id.
     * 
     */
    public Optional<Output<JobReferenceArgs>> reference() {
        return Optional.ofNullable(this.reference);
    }

    @Import(name="region", required=true)
    private Output<String> region;

    public Output<String> region() {
        return this.region;
    }

    /**
     * Optional. A unique id used to identify the request. If the server receives two SubmitJobRequest (https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#google.cloud.dataproc.v1.SubmitJobRequest)s with the same id, then the second request will be ignored and the first Job created and stored in the backend is returned.It is recommended to always set this value to a UUID (https://en.wikipedia.org/wiki/Universally_unique_identifier).The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). The maximum length is 40 characters.
     * 
     */
    @Import(name="requestId")
    private @Nullable Output<String> requestId;

    /**
     * @return Optional. A unique id used to identify the request. If the server receives two SubmitJobRequest (https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#google.cloud.dataproc.v1.SubmitJobRequest)s with the same id, then the second request will be ignored and the first Job created and stored in the backend is returned.It is recommended to always set this value to a UUID (https://en.wikipedia.org/wiki/Universally_unique_identifier).The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). The maximum length is 40 characters.
     * 
     */
    public Optional<Output<String>> requestId() {
        return Optional.ofNullable(this.requestId);
    }

    /**
     * Optional. Job scheduling configuration.
     * 
     */
    @Import(name="scheduling")
    private @Nullable Output<JobSchedulingArgs> scheduling;

    /**
     * @return Optional. Job scheduling configuration.
     * 
     */
    public Optional<Output<JobSchedulingArgs>> scheduling() {
        return Optional.ofNullable(this.scheduling);
    }

    /**
     * Optional. Job is a Spark job.
     * 
     */
    @Import(name="sparkJob")
    private @Nullable Output<SparkJobArgs> sparkJob;

    /**
     * @return Optional. Job is a Spark job.
     * 
     */
    public Optional<Output<SparkJobArgs>> sparkJob() {
        return Optional.ofNullable(this.sparkJob);
    }

    /**
     * Optional. Job is a SparkR job.
     * 
     */
    @Import(name="sparkRJob")
    private @Nullable Output<SparkRJobArgs> sparkRJob;

    /**
     * @return Optional. Job is a SparkR job.
     * 
     */
    public Optional<Output<SparkRJobArgs>> sparkRJob() {
        return Optional.ofNullable(this.sparkRJob);
    }

    /**
     * Optional. Job is a SparkSql job.
     * 
     */
    @Import(name="sparkSqlJob")
    private @Nullable Output<SparkSqlJobArgs> sparkSqlJob;

    /**
     * @return Optional. Job is a SparkSql job.
     * 
     */
    public Optional<Output<SparkSqlJobArgs>> sparkSqlJob() {
        return Optional.ofNullable(this.sparkSqlJob);
    }

    private JobArgs() {}

    private JobArgs(JobArgs $) {
        this.hadoopJob = $.hadoopJob;
        this.hiveJob = $.hiveJob;
        this.labels = $.labels;
        this.pigJob = $.pigJob;
        this.placement = $.placement;
        this.prestoJob = $.prestoJob;
        this.project = $.project;
        this.pysparkJob = $.pysparkJob;
        this.reference = $.reference;
        this.region = $.region;
        this.requestId = $.requestId;
        this.scheduling = $.scheduling;
        this.sparkJob = $.sparkJob;
        this.sparkRJob = $.sparkRJob;
        this.sparkSqlJob = $.sparkSqlJob;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(JobArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private JobArgs $;

        public Builder() {
            $ = new JobArgs();
        }

        public Builder(JobArgs defaults) {
            $ = new JobArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param hadoopJob Optional. Job is a Hadoop job.
         * 
         * @return builder
         * 
         */
        public Builder hadoopJob(@Nullable Output<HadoopJobArgs> hadoopJob) {
            $.hadoopJob = hadoopJob;
            return this;
        }

        /**
         * @param hadoopJob Optional. Job is a Hadoop job.
         * 
         * @return builder
         * 
         */
        public Builder hadoopJob(HadoopJobArgs hadoopJob) {
            return hadoopJob(Output.of(hadoopJob));
        }

        /**
         * @param hiveJob Optional. Job is a Hive job.
         * 
         * @return builder
         * 
         */
        public Builder hiveJob(@Nullable Output<HiveJobArgs> hiveJob) {
            $.hiveJob = hiveJob;
            return this;
        }

        /**
         * @param hiveJob Optional. Job is a Hive job.
         * 
         * @return builder
         * 
         */
        public Builder hiveJob(HiveJobArgs hiveJob) {
            return hiveJob(Output.of(hiveJob));
        }

        /**
         * @param labels Optional. The labels to associate with this job. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a job.
         * 
         * @return builder
         * 
         */
        public Builder labels(@Nullable Output<Map<String,String>> labels) {
            $.labels = labels;
            return this;
        }

        /**
         * @param labels Optional. The labels to associate with this job. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a job.
         * 
         * @return builder
         * 
         */
        public Builder labels(Map<String,String> labels) {
            return labels(Output.of(labels));
        }

        /**
         * @param pigJob Optional. Job is a Pig job.
         * 
         * @return builder
         * 
         */
        public Builder pigJob(@Nullable Output<PigJobArgs> pigJob) {
            $.pigJob = pigJob;
            return this;
        }

        /**
         * @param pigJob Optional. Job is a Pig job.
         * 
         * @return builder
         * 
         */
        public Builder pigJob(PigJobArgs pigJob) {
            return pigJob(Output.of(pigJob));
        }

        /**
         * @param placement Job information, including how, when, and where to run the job.
         * 
         * @return builder
         * 
         */
        public Builder placement(Output<JobPlacementArgs> placement) {
            $.placement = placement;
            return this;
        }

        /**
         * @param placement Job information, including how, when, and where to run the job.
         * 
         * @return builder
         * 
         */
        public Builder placement(JobPlacementArgs placement) {
            return placement(Output.of(placement));
        }

        /**
         * @param prestoJob Optional. Job is a Presto job.
         * 
         * @return builder
         * 
         */
        public Builder prestoJob(@Nullable Output<PrestoJobArgs> prestoJob) {
            $.prestoJob = prestoJob;
            return this;
        }

        /**
         * @param prestoJob Optional. Job is a Presto job.
         * 
         * @return builder
         * 
         */
        public Builder prestoJob(PrestoJobArgs prestoJob) {
            return prestoJob(Output.of(prestoJob));
        }

        public Builder project(@Nullable Output<String> project) {
            $.project = project;
            return this;
        }

        public Builder project(String project) {
            return project(Output.of(project));
        }

        /**
         * @param pysparkJob Optional. Job is a PySpark job.
         * 
         * @return builder
         * 
         */
        public Builder pysparkJob(@Nullable Output<PySparkJobArgs> pysparkJob) {
            $.pysparkJob = pysparkJob;
            return this;
        }

        /**
         * @param pysparkJob Optional. Job is a PySpark job.
         * 
         * @return builder
         * 
         */
        public Builder pysparkJob(PySparkJobArgs pysparkJob) {
            return pysparkJob(Output.of(pysparkJob));
        }

        /**
         * @param reference Optional. The fully qualified reference to the job, which can be used to obtain the equivalent REST path of the job resource. If this property is not specified when a job is created, the server generates a job_id.
         * 
         * @return builder
         * 
         */
        public Builder reference(@Nullable Output<JobReferenceArgs> reference) {
            $.reference = reference;
            return this;
        }

        /**
         * @param reference Optional. The fully qualified reference to the job, which can be used to obtain the equivalent REST path of the job resource. If this property is not specified when a job is created, the server generates a job_id.
         * 
         * @return builder
         * 
         */
        public Builder reference(JobReferenceArgs reference) {
            return reference(Output.of(reference));
        }

        public Builder region(Output<String> region) {
            $.region = region;
            return this;
        }

        public Builder region(String region) {
            return region(Output.of(region));
        }

        /**
         * @param requestId Optional. A unique id used to identify the request. If the server receives two SubmitJobRequest (https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#google.cloud.dataproc.v1.SubmitJobRequest)s with the same id, then the second request will be ignored and the first Job created and stored in the backend is returned.It is recommended to always set this value to a UUID (https://en.wikipedia.org/wiki/Universally_unique_identifier).The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). The maximum length is 40 characters.
         * 
         * @return builder
         * 
         */
        public Builder requestId(@Nullable Output<String> requestId) {
            $.requestId = requestId;
            return this;
        }

        /**
         * @param requestId Optional. A unique id used to identify the request. If the server receives two SubmitJobRequest (https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#google.cloud.dataproc.v1.SubmitJobRequest)s with the same id, then the second request will be ignored and the first Job created and stored in the backend is returned.It is recommended to always set this value to a UUID (https://en.wikipedia.org/wiki/Universally_unique_identifier).The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). The maximum length is 40 characters.
         * 
         * @return builder
         * 
         */
        public Builder requestId(String requestId) {
            return requestId(Output.of(requestId));
        }

        /**
         * @param scheduling Optional. Job scheduling configuration.
         * 
         * @return builder
         * 
         */
        public Builder scheduling(@Nullable Output<JobSchedulingArgs> scheduling) {
            $.scheduling = scheduling;
            return this;
        }

        /**
         * @param scheduling Optional. Job scheduling configuration.
         * 
         * @return builder
         * 
         */
        public Builder scheduling(JobSchedulingArgs scheduling) {
            return scheduling(Output.of(scheduling));
        }

        /**
         * @param sparkJob Optional. Job is a Spark job.
         * 
         * @return builder
         * 
         */
        public Builder sparkJob(@Nullable Output<SparkJobArgs> sparkJob) {
            $.sparkJob = sparkJob;
            return this;
        }

        /**
         * @param sparkJob Optional. Job is a Spark job.
         * 
         * @return builder
         * 
         */
        public Builder sparkJob(SparkJobArgs sparkJob) {
            return sparkJob(Output.of(sparkJob));
        }

        /**
         * @param sparkRJob Optional. Job is a SparkR job.
         * 
         * @return builder
         * 
         */
        public Builder sparkRJob(@Nullable Output<SparkRJobArgs> sparkRJob) {
            $.sparkRJob = sparkRJob;
            return this;
        }

        /**
         * @param sparkRJob Optional. Job is a SparkR job.
         * 
         * @return builder
         * 
         */
        public Builder sparkRJob(SparkRJobArgs sparkRJob) {
            return sparkRJob(Output.of(sparkRJob));
        }

        /**
         * @param sparkSqlJob Optional. Job is a SparkSql job.
         * 
         * @return builder
         * 
         */
        public Builder sparkSqlJob(@Nullable Output<SparkSqlJobArgs> sparkSqlJob) {
            $.sparkSqlJob = sparkSqlJob;
            return this;
        }

        /**
         * @param sparkSqlJob Optional. Job is a SparkSql job.
         * 
         * @return builder
         * 
         */
        public Builder sparkSqlJob(SparkSqlJobArgs sparkSqlJob) {
            return sparkSqlJob(Output.of(sparkSqlJob));
        }

        public JobArgs build() {
            $.placement = Objects.requireNonNull($.placement, "expected parameter 'placement' to be non-null");
            $.region = Objects.requireNonNull($.region, "expected parameter 'region' to be non-null");
            return $;
        }
    }

}
