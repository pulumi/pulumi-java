// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package io.pulumi.googlenative.dataproc_v1.inputs;

import io.pulumi.core.Output;
import io.pulumi.core.annotations.Import;
import java.lang.Double;
import java.lang.String;
import java.util.Objects;
import javax.annotation.Nullable;


/**
 * Basic autoscaling configurations for Spark Standalone.
 * 
 */
public final class SparkStandaloneAutoscalingConfigArgs extends io.pulumi.resources.ResourceArgs {

    public static final SparkStandaloneAutoscalingConfigArgs Empty = new SparkStandaloneAutoscalingConfigArgs();

    /**
     * Timeout for Spark graceful decommissioning of spark workers. Specifies the duration to wait for spark worker to complete spark decomissioning tasks before forcefully removing workers. Only applicable to downscaling operations.Bounds: 0s, 1d.
     * 
     */
    @Import(name="gracefulDecommissionTimeout", required=true)
      private final Output<String> gracefulDecommissionTimeout;

    public Output<String> getGracefulDecommissionTimeout() {
        return this.gracefulDecommissionTimeout;
    }

    /**
     * Fraction of required executors to remove from Spark Serverless clusters. A scale-down factor of 1.0 will result in scaling down so that there are no more executors for the Spark Job.(more aggressive scaling). A scale-down factor closer to 0 will result in a smaller magnitude of scaling donw (less aggressive scaling).Bounds: 0.0, 1.0.
     * 
     */
    @Import(name="scaleDownFactor", required=true)
      private final Output<Double> scaleDownFactor;

    public Output<Double> getScaleDownFactor() {
        return this.scaleDownFactor;
    }

    /**
     * Optional. Minimum scale-down threshold as a fraction of total cluster size before scaling occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0 means the autoscaler will scale down on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
     * 
     */
    @Import(name="scaleDownMinWorkerFraction")
      private final @Nullable Output<Double> scaleDownMinWorkerFraction;

    public Output<Double> getScaleDownMinWorkerFraction() {
        return this.scaleDownMinWorkerFraction == null ? Output.empty() : this.scaleDownMinWorkerFraction;
    }

    /**
     * Fraction of required workers to add to Spark Standalone clusters. A scale-up factor of 1.0 will result in scaling up so that there are no more required workers for the Spark Job (more aggressive scaling). A scale-up factor closer to 0 will result in a smaller magnitude of scaling up (less aggressive scaling).Bounds: 0.0, 1.0.
     * 
     */
    @Import(name="scaleUpFactor", required=true)
      private final Output<Double> scaleUpFactor;

    public Output<Double> getScaleUpFactor() {
        return this.scaleUpFactor;
    }

    /**
     * Optional. Minimum scale-up threshold as a fraction of total cluster size before scaling occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of 0 means the autoscaler will scale up on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
     * 
     */
    @Import(name="scaleUpMinWorkerFraction")
      private final @Nullable Output<Double> scaleUpMinWorkerFraction;

    public Output<Double> getScaleUpMinWorkerFraction() {
        return this.scaleUpMinWorkerFraction == null ? Output.empty() : this.scaleUpMinWorkerFraction;
    }

    public SparkStandaloneAutoscalingConfigArgs(
        Output<String> gracefulDecommissionTimeout,
        Output<Double> scaleDownFactor,
        @Nullable Output<Double> scaleDownMinWorkerFraction,
        Output<Double> scaleUpFactor,
        @Nullable Output<Double> scaleUpMinWorkerFraction) {
        this.gracefulDecommissionTimeout = Objects.requireNonNull(gracefulDecommissionTimeout, "expected parameter 'gracefulDecommissionTimeout' to be non-null");
        this.scaleDownFactor = Objects.requireNonNull(scaleDownFactor, "expected parameter 'scaleDownFactor' to be non-null");
        this.scaleDownMinWorkerFraction = scaleDownMinWorkerFraction;
        this.scaleUpFactor = Objects.requireNonNull(scaleUpFactor, "expected parameter 'scaleUpFactor' to be non-null");
        this.scaleUpMinWorkerFraction = scaleUpMinWorkerFraction;
    }

    private SparkStandaloneAutoscalingConfigArgs() {
        this.gracefulDecommissionTimeout = Output.empty();
        this.scaleDownFactor = Output.empty();
        this.scaleDownMinWorkerFraction = Output.empty();
        this.scaleUpFactor = Output.empty();
        this.scaleUpMinWorkerFraction = Output.empty();
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(SparkStandaloneAutoscalingConfigArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private Output<String> gracefulDecommissionTimeout;
        private Output<Double> scaleDownFactor;
        private @Nullable Output<Double> scaleDownMinWorkerFraction;
        private Output<Double> scaleUpFactor;
        private @Nullable Output<Double> scaleUpMinWorkerFraction;

        public Builder() {
    	      // Empty
        }

        public Builder(SparkStandaloneAutoscalingConfigArgs defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.gracefulDecommissionTimeout = defaults.gracefulDecommissionTimeout;
    	      this.scaleDownFactor = defaults.scaleDownFactor;
    	      this.scaleDownMinWorkerFraction = defaults.scaleDownMinWorkerFraction;
    	      this.scaleUpFactor = defaults.scaleUpFactor;
    	      this.scaleUpMinWorkerFraction = defaults.scaleUpMinWorkerFraction;
        }

        public Builder gracefulDecommissionTimeout(Output<String> gracefulDecommissionTimeout) {
            this.gracefulDecommissionTimeout = Objects.requireNonNull(gracefulDecommissionTimeout);
            return this;
        }
        public Builder gracefulDecommissionTimeout(String gracefulDecommissionTimeout) {
            this.gracefulDecommissionTimeout = Output.of(Objects.requireNonNull(gracefulDecommissionTimeout));
            return this;
        }
        public Builder scaleDownFactor(Output<Double> scaleDownFactor) {
            this.scaleDownFactor = Objects.requireNonNull(scaleDownFactor);
            return this;
        }
        public Builder scaleDownFactor(Double scaleDownFactor) {
            this.scaleDownFactor = Output.of(Objects.requireNonNull(scaleDownFactor));
            return this;
        }
        public Builder scaleDownMinWorkerFraction(@Nullable Output<Double> scaleDownMinWorkerFraction) {
            this.scaleDownMinWorkerFraction = scaleDownMinWorkerFraction;
            return this;
        }
        public Builder scaleDownMinWorkerFraction(@Nullable Double scaleDownMinWorkerFraction) {
            this.scaleDownMinWorkerFraction = Output.ofNullable(scaleDownMinWorkerFraction);
            return this;
        }
        public Builder scaleUpFactor(Output<Double> scaleUpFactor) {
            this.scaleUpFactor = Objects.requireNonNull(scaleUpFactor);
            return this;
        }
        public Builder scaleUpFactor(Double scaleUpFactor) {
            this.scaleUpFactor = Output.of(Objects.requireNonNull(scaleUpFactor));
            return this;
        }
        public Builder scaleUpMinWorkerFraction(@Nullable Output<Double> scaleUpMinWorkerFraction) {
            this.scaleUpMinWorkerFraction = scaleUpMinWorkerFraction;
            return this;
        }
        public Builder scaleUpMinWorkerFraction(@Nullable Double scaleUpMinWorkerFraction) {
            this.scaleUpMinWorkerFraction = Output.ofNullable(scaleUpMinWorkerFraction);
            return this;
        }        public SparkStandaloneAutoscalingConfigArgs build() {
            return new SparkStandaloneAutoscalingConfigArgs(gracefulDecommissionTimeout, scaleDownFactor, scaleDownMinWorkerFraction, scaleUpFactor, scaleUpMinWorkerFraction);
        }
    }
}
