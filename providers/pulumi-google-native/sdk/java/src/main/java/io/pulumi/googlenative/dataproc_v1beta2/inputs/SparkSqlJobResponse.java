// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package io.pulumi.googlenative.dataproc_v1beta2.inputs;

import io.pulumi.core.annotations.Import;
import io.pulumi.googlenative.dataproc_v1beta2.inputs.LoggingConfigResponse;
import io.pulumi.googlenative.dataproc_v1beta2.inputs.QueryListResponse;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;


/**
 * A Dataproc job for running Apache Spark SQL (http://spark.apache.org/sql/) queries.
 * 
 */
public final class SparkSqlJobResponse extends io.pulumi.resources.InvokeArgs {

    public static final SparkSqlJobResponse Empty = new SparkSqlJobResponse();

    /**
     * Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
     * 
     */
    @Import(name="jarFileUris", required=true)
      private final List<String> jarFileUris;

    public List<String> jarFileUris() {
        return this.jarFileUris;
    }

    /**
     * Optional. The runtime log config for job execution.
     * 
     */
    @Import(name="loggingConfig", required=true)
      private final LoggingConfigResponse loggingConfig;

    public LoggingConfigResponse loggingConfig() {
        return this.loggingConfig;
    }

    /**
     * Optional. A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Dataproc API may be overwritten.
     * 
     */
    @Import(name="properties", required=true)
      private final Map<String,String> properties;

    public Map<String,String> properties() {
        return this.properties;
    }

    /**
     * The HCFS URI of the script that contains SQL queries.
     * 
     */
    @Import(name="queryFileUri", required=true)
      private final String queryFileUri;

    public String queryFileUri() {
        return this.queryFileUri;
    }

    /**
     * A list of queries.
     * 
     */
    @Import(name="queryList", required=true)
      private final QueryListResponse queryList;

    public QueryListResponse queryList() {
        return this.queryList;
    }

    /**
     * Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET name="value";).
     * 
     */
    @Import(name="scriptVariables", required=true)
      private final Map<String,String> scriptVariables;

    public Map<String,String> scriptVariables() {
        return this.scriptVariables;
    }

    public SparkSqlJobResponse(
        List<String> jarFileUris,
        LoggingConfigResponse loggingConfig,
        Map<String,String> properties,
        String queryFileUri,
        QueryListResponse queryList,
        Map<String,String> scriptVariables) {
        this.jarFileUris = Objects.requireNonNull(jarFileUris, "expected parameter 'jarFileUris' to be non-null");
        this.loggingConfig = Objects.requireNonNull(loggingConfig, "expected parameter 'loggingConfig' to be non-null");
        this.properties = Objects.requireNonNull(properties, "expected parameter 'properties' to be non-null");
        this.queryFileUri = Objects.requireNonNull(queryFileUri, "expected parameter 'queryFileUri' to be non-null");
        this.queryList = Objects.requireNonNull(queryList, "expected parameter 'queryList' to be non-null");
        this.scriptVariables = Objects.requireNonNull(scriptVariables, "expected parameter 'scriptVariables' to be non-null");
    }

    private SparkSqlJobResponse() {
        this.jarFileUris = List.of();
        this.loggingConfig = null;
        this.properties = Map.of();
        this.queryFileUri = null;
        this.queryList = null;
        this.scriptVariables = Map.of();
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(SparkSqlJobResponse defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private List<String> jarFileUris;
        private LoggingConfigResponse loggingConfig;
        private Map<String,String> properties;
        private String queryFileUri;
        private QueryListResponse queryList;
        private Map<String,String> scriptVariables;

        public Builder() {
    	      // Empty
        }

        public Builder(SparkSqlJobResponse defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.jarFileUris = defaults.jarFileUris;
    	      this.loggingConfig = defaults.loggingConfig;
    	      this.properties = defaults.properties;
    	      this.queryFileUri = defaults.queryFileUri;
    	      this.queryList = defaults.queryList;
    	      this.scriptVariables = defaults.scriptVariables;
        }

        public Builder jarFileUris(List<String> jarFileUris) {
            this.jarFileUris = Objects.requireNonNull(jarFileUris);
            return this;
        }
        public Builder jarFileUris(String... jarFileUris) {
            return jarFileUris(List.of(jarFileUris));
        }
        public Builder loggingConfig(LoggingConfigResponse loggingConfig) {
            this.loggingConfig = Objects.requireNonNull(loggingConfig);
            return this;
        }
        public Builder properties(Map<String,String> properties) {
            this.properties = Objects.requireNonNull(properties);
            return this;
        }
        public Builder queryFileUri(String queryFileUri) {
            this.queryFileUri = Objects.requireNonNull(queryFileUri);
            return this;
        }
        public Builder queryList(QueryListResponse queryList) {
            this.queryList = Objects.requireNonNull(queryList);
            return this;
        }
        public Builder scriptVariables(Map<String,String> scriptVariables) {
            this.scriptVariables = Objects.requireNonNull(scriptVariables);
            return this;
        }        public SparkSqlJobResponse build() {
            return new SparkSqlJobResponse(jarFileUris, loggingConfig, properties, queryFileUri, queryList, scriptVariables);
        }
    }
}
